{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Jun 30 10:41:49 2019\n",
    "\n",
    "@author: sahil\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Get the data\n",
    "def get_data():\n",
    "\treturn_period = 21\n",
    "\n",
    "\tstk_tickers = ['MSFT', 'IBM', 'GOOGL']\n",
    "\tccy_tickers = ['DEXJPUS', 'DEXUSUK']\n",
    "\tidx_tickers = ['SP500', 'DJIA', 'VIXCLS']\n",
    "\n",
    "\tstk_data = web.DataReader(stk_tickers, 'yahoo')\n",
    "\tccy_data = web.DataReader(ccy_tickers, 'fred')\n",
    "\tidx_data = web.DataReader(idx_tickers, 'fred')\n",
    "\n",
    "\tY = np.log(stk_data.loc[:, ('Adj Close', 'MSFT')]).diff(return_period).shift(-return_period)\n",
    "\tY.name = Y.name[-1]+'_pred'\n",
    "\n",
    "\tX1 = np.log(stk_data.loc[:, ('Adj Close', ('GOOGL', 'IBM'))]).diff(return_period)\n",
    "\tX1.columns = X1.columns.droplevel()\n",
    "\tX2 = np.log(ccy_data).diff(return_period)\n",
    "\tX3 = np.log(idx_data).diff(return_period)\n",
    "\n",
    "\tX4 = pd.concat([Y.diff(i) for i in [21, 63, 126,252]], axis=1).dropna()\n",
    "\tX4.columns = ['1M', '3M', '6M', '1Y']\n",
    "\n",
    "\tX = pd.concat([X1, X2, X3, X4], axis=1)\n",
    "\n",
    "\tdata = pd.concat([Y, X], axis=1).dropna()\n",
    "\tY = data.loc[:, Y.name]\n",
    "\tX = data.loc[:, X.columns]\n",
    "\treturn X, Y\n",
    "\n",
    "X, Y= get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([Y, X], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2006, 12)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data to the version compatible with supervised learning, where all the dependent variables are lagged along with other IVs.\n",
    "Function to be used as follows:\n",
    "- data: Sequence of observations as a list or 2D NumPy array. Required.\n",
    "- n_in: Number of lag observations as input (X). Values may be between [1..len(data)] Optional. Defaults to 1.\n",
    "- n_out: Number of observations as output (y). Values may be between [0..len(data)-1]. Optional. Defaults to 1.\n",
    "- dropnan: Boolean whether or not to drop rows with NaN values. Optional. Defaults to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to the data compatible for supervised learning problem\n",
    "#The return of the stock \n",
    "#Keep the name intact\n",
    "def series_to_supervised(data, lag=1, dropnan=True):\n",
    "    n_vars = data.shape[1]\n",
    "    df = pd.DataFrame(data)    \n",
    "    cols, names = list(), list()\n",
    "    for i in range(lag, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('%s(t-%d)' % (df.columns[j], i)) for j in range(n_vars)]\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    agg = pd.DataFrame(data.iloc[:,0]).join(agg)\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed= series_to_supervised(dataset,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSFT_pred</th>\n",
       "      <th>MSFT_pred(t-1)</th>\n",
       "      <th>GOOGL(t-1)</th>\n",
       "      <th>IBM(t-1)</th>\n",
       "      <th>DEXJPUS(t-1)</th>\n",
       "      <th>DEXUSUK(t-1)</th>\n",
       "      <th>SP500(t-1)</th>\n",
       "      <th>DJIA(t-1)</th>\n",
       "      <th>VIXCLS(t-1)</th>\n",
       "      <th>1M(t-1)</th>\n",
       "      <th>3M(t-1)</th>\n",
       "      <th>6M(t-1)</th>\n",
       "      <th>1Y(t-1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>-0.015788</td>\n",
       "      <td>-0.001430</td>\n",
       "      <td>0.055329</td>\n",
       "      <td>0.015719</td>\n",
       "      <td>-0.014243</td>\n",
       "      <td>-0.014930</td>\n",
       "      <td>0.037784</td>\n",
       "      <td>0.025045</td>\n",
       "      <td>-0.022460</td>\n",
       "      <td>-0.041166</td>\n",
       "      <td>-0.137312</td>\n",
       "      <td>-0.078562</td>\n",
       "      <td>0.076488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>-0.008248</td>\n",
       "      <td>-0.015788</td>\n",
       "      <td>0.049571</td>\n",
       "      <td>0.015426</td>\n",
       "      <td>-0.008988</td>\n",
       "      <td>-0.006013</td>\n",
       "      <td>0.037769</td>\n",
       "      <td>0.028544</td>\n",
       "      <td>-0.036162</td>\n",
       "      <td>-0.054624</td>\n",
       "      <td>-0.120203</td>\n",
       "      <td>-0.058879</td>\n",
       "      <td>0.090435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06</th>\n",
       "      <td>-0.021747</td>\n",
       "      <td>-0.008248</td>\n",
       "      <td>0.051737</td>\n",
       "      <td>0.014108</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.019490</td>\n",
       "      <td>0.042249</td>\n",
       "      <td>0.031519</td>\n",
       "      <td>-0.055427</td>\n",
       "      <td>-0.050560</td>\n",
       "      <td>-0.113445</td>\n",
       "      <td>-0.053893</td>\n",
       "      <td>0.085373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-07</th>\n",
       "      <td>-0.011252</td>\n",
       "      <td>-0.021747</td>\n",
       "      <td>0.043917</td>\n",
       "      <td>0.031710</td>\n",
       "      <td>-0.012074</td>\n",
       "      <td>-0.019309</td>\n",
       "      <td>0.036429</td>\n",
       "      <td>0.028162</td>\n",
       "      <td>-0.019352</td>\n",
       "      <td>-0.091807</td>\n",
       "      <td>-0.112116</td>\n",
       "      <td>-0.075489</td>\n",
       "      <td>0.072184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-10</th>\n",
       "      <td>-0.008898</td>\n",
       "      <td>-0.011252</td>\n",
       "      <td>0.042924</td>\n",
       "      <td>0.020143</td>\n",
       "      <td>-0.009707</td>\n",
       "      <td>-0.011057</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>0.026446</td>\n",
       "      <td>-0.006397</td>\n",
       "      <td>-0.060340</td>\n",
       "      <td>-0.098501</td>\n",
       "      <td>-0.020871</td>\n",
       "      <td>0.079145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MSFT_pred  MSFT_pred(t-1)  GOOGL(t-1)  IBM(t-1)  DEXJPUS(t-1)  \\\n",
       "2011-01-04  -0.015788       -0.001430    0.055329  0.015719     -0.014243   \n",
       "2011-01-05  -0.008248       -0.015788    0.049571  0.015426     -0.008988   \n",
       "2011-01-06  -0.021747       -0.008248    0.051737  0.014108      0.002165   \n",
       "2011-01-07  -0.011252       -0.021747    0.043917  0.031710     -0.012074   \n",
       "2011-01-10  -0.008898       -0.011252    0.042924  0.020143     -0.009707   \n",
       "\n",
       "            DEXUSUK(t-1)  SP500(t-1)  DJIA(t-1)  VIXCLS(t-1)   1M(t-1)  \\\n",
       "2011-01-04     -0.014930    0.037784   0.025045    -0.022460 -0.041166   \n",
       "2011-01-05     -0.006013    0.037769   0.028544    -0.036162 -0.054624   \n",
       "2011-01-06     -0.019490    0.042249   0.031519    -0.055427 -0.050560   \n",
       "2011-01-07     -0.019309    0.036429   0.028162    -0.019352 -0.091807   \n",
       "2011-01-10     -0.011057    0.030747   0.026446    -0.006397 -0.060340   \n",
       "\n",
       "             3M(t-1)   6M(t-1)   1Y(t-1)  \n",
       "2011-01-04 -0.137312 -0.078562  0.076488  \n",
       "2011-01-05 -0.120203 -0.058879  0.090435  \n",
       "2011-01-06 -0.113445 -0.053893  0.085373  \n",
       "2011-01-07 -0.112116 -0.075489  0.072184  \n",
       "2011-01-10 -0.098501 -0.020871  0.079145  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop Column that are not needed all the columns related to the current time period of the IVs\n",
    "#reframed=reframed.iloc[:,0:int(reframed.shape[1]/2+1)]\n",
    "reframed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= np.array(reframed[\"MSFT_pred\"])\n",
    "X = np.array(reframed.loc[:, reframed.columns != 'MSFT_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out validation dataset for the end\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler().fit(X)\n",
    "# StandardisedX = pd.DataFrame(scaler.fit_transform(X))\n",
    "validation_size = 0.2\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1604, 1, 12) (1604,) (401, 1, 12) (401,)\n"
     ]
    }
   ],
   "source": [
    "X_train= X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_validation= X_validation.reshape((X_validation.shape[0], 1, X_validation.shape[1]))\n",
    "print(X_train.shape, Y_train.shape, X_validation.shape, Y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.00540012,  0.06675433,  0.01397417, ...,  0.00807343,\n",
       "         -0.03000404,  0.0606205 ]],\n",
       "\n",
       "       [[ 0.04305776,  0.06377137, -0.03087694, ...,  0.0694208 ,\n",
       "          0.10786274,  0.01224553]],\n",
       "\n",
       "       [[ 0.06508718, -0.02935815,  0.00292757, ...,  0.04750487,\n",
       "          0.11596184,  0.05083729]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.07566343, -0.05495538,  0.00909798, ...,  0.04853943,\n",
       "          0.08134031,  0.1036531 ]],\n",
       "\n",
       "       [[ 0.02460392, -0.00218574,  0.04347873, ..., -0.02506848,\n",
       "          0.09062454,  0.05350333]],\n",
       "\n",
       "       [[ 0.08047208,  0.00354015,  0.02583158, ..., -0.04454768,\n",
       "          0.0882513 ,  0.04232268]]])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1604 samples, validate on 401 samples\n",
      "Epoch 1/50\n",
      "1604/1604 [==============================] - 1s 479us/step - loss: 0.0415 - val_loss: 0.0357\n",
      "Epoch 2/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0307 - val_loss: 0.0257\n",
      "Epoch 3/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0233 - val_loss: 0.0205\n",
      "Epoch 4/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0211 - val_loss: 0.0196\n",
      "Epoch 5/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0205 - val_loss: 0.0193\n",
      "Epoch 6/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0199 - val_loss: 0.0189\n",
      "Epoch 7/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0194 - val_loss: 0.0186\n",
      "Epoch 8/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0190 - val_loss: 0.0182\n",
      "Epoch 9/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0186 - val_loss: 0.0179\n",
      "Epoch 10/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0182 - val_loss: 0.0175\n",
      "Epoch 11/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0178 - val_loss: 0.0171\n",
      "Epoch 12/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0173 - val_loss: 0.0168\n",
      "Epoch 13/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0170 - val_loss: 0.0164\n",
      "Epoch 14/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0166 - val_loss: 0.0161\n",
      "Epoch 15/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0163 - val_loss: 0.0158\n",
      "Epoch 16/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0160 - val_loss: 0.0156\n",
      "Epoch 17/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0159 - val_loss: 0.0154\n",
      "Epoch 18/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0157 - val_loss: 0.0153\n",
      "Epoch 19/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0156 - val_loss: 0.0152\n",
      "Epoch 20/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0155 - val_loss: 0.0152\n",
      "Epoch 21/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0154 - val_loss: 0.0151\n",
      "Epoch 22/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0154 - val_loss: 0.0150\n",
      "Epoch 23/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0154 - val_loss: 0.0150\n",
      "Epoch 24/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0153 - val_loss: 0.0152\n",
      "Epoch 25/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0154 - val_loss: 0.0151\n",
      "Epoch 26/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0154 - val_loss: 0.0150\n",
      "Epoch 27/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 28/50\n",
      "1604/1604 [==============================] - 0s 20us/step - loss: 0.0154 - val_loss: 0.0150\n",
      "Epoch 29/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 30/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 31/50\n",
      "1604/1604 [==============================] - 0s 27us/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 32/50\n",
      "1604/1604 [==============================] - 0s 24us/step - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 33/50\n",
      "1604/1604 [==============================] - 0s 23us/step - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 34/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 35/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0153 - val_loss: 0.0151\n",
      "Epoch 36/50\n",
      "1604/1604 [==============================] - 0s 24us/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 37/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 38/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 39/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 40/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 41/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 42/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0153 - val_loss: 0.0149\n",
      "Epoch 43/50\n",
      "1604/1604 [==============================] - 0s 20us/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 44/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 45/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 46/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0152 - val_loss: 0.0149\n",
      "Epoch 47/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0152 - val_loss: 0.0150\n",
      "Epoch 48/50\n",
      "1604/1604 [==============================] - 0s 22us/step - loss: 0.0153 - val_loss: 0.0150\n",
      "Epoch 49/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0152 - val_loss: 0.0150\n",
      "Epoch 50/50\n",
      "1604/1604 [==============================] - 0s 25us/step - loss: 0.0153 - val_loss: 0.0149\n"
     ]
    }
   ],
   "source": [
    "# design network\n",
    "from matplotlib import pyplot\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(X_train, Y_train, epochs=50, batch_size=72, validation_data=(X_validation, Y_validation), verbose=1, shuffle=False)\n",
    "# plot history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Wt4XNV97/Hvf2Y0Gt2sO8ayfCM2DhhzszEkJCSEAoaQGMKlDqGhPTw4aUpPT3vgBPoc0iZtz0nOC3JpaVpSnBByuORAaNzGBEKAQAgXy2CCzc3GGCxfsGRLtu6ayzov1h5pJMvW2JY0tvbv8zz7mZk9a+9Z24j5zdprr7XNOYeIiEik0BUQEZGjgwJBREQABYKIiAQUCCIiAigQREQkoEAQERFAgSAiIgEFgoiIAAoEEREJxApdgUNRV1fnZs+eXehqiIgcU9auXdvqnKsfrdwxFQizZ8+mqamp0NUQETmmmNl7+ZTTKSMREQEUCCIiElAgiIgIcIz1IYiIHKpkMklzczO9vb2Frsq4SyQSNDY2UlRUdFjbKxBEZFJrbm6moqKC2bNnY2aFrs64cc6xe/dumpubmTNnzmHtQ6eMRGRS6+3tpba2dlKHAYCZUVtbe0QtIQWCiEx6kz0Mso70OEMRCPf8bgurXt1e6GqIiBzVQhEI97/0PqvWKRBEZOK1t7fzz//8z4e83aWXXkp7e/s41OjAQhEINWVx2rr7C10NEQmhAwVCOp0+6HarV6+mqqpqvKo1olAEQrUCQUQK5NZbb+Wdd97h9NNP56yzzuL888/n2muvZeHChQBcfvnlLFq0iAULFnDXXXcNbDd79mxaW1vZsmULJ510EjfeeCMLFizgoosuoqenZ1zqGorLTmtK47R1KRBEwu7r/7GB17fvG9N9ntwwhb/5zIIDvv/Nb36T9evXs27dOp5++mk+/elPs379+oFLQ1euXElNTQ09PT2cddZZXHnlldTW1g7Zx8aNG7n//vv5wQ9+wDXXXMPDDz/MddddN6bHASEJhOqyOO09SdIZRzQSjqsNROTotGTJkiHjBL73ve/xyCOPALB161Y2bty4XyDMmTOH008/HYBFixaxZcuWcalbKAKhprQI52BvT5KasnihqyMiBXKwX/ITpaysbOD5008/zRNPPMHzzz9PaWkpn/zkJ0ccR1BcXDzwPBqNjtspo9D0IQDs0WkjEZlgFRUVdHR0jPje3r17qa6uprS0lDfffJMXXnhhgms3VF6BYGZLzewtM9tkZreO8H6xmT0YvP+imc0e9v5MM+s0s5vz3edYqi71gaCOZRGZaLW1tZx77rmccsop3HLLLUPeW7p0KalUilNPPZXbb7+dc845p0C19EY9ZWRmUeBO4EKgGVhjZqucc6/nFLsBaHPOzTWz5cC3gD/Mef/bwKOHuM8xU6MWgogU0H333Tfi+uLiYh599NER38v2E9TV1bF+/fqB9TfffPOI5cdCPi2EJcAm59xm51w/8ACwbFiZZcA9wfOHgAssGENtZpcDm4ENh7jPMZM9ZdSuFoKIyAHlEwjTga05r5uDdSOWcc6lgL1ArZmVAV8Fvn4Y+xwzNaXZFkJyvD5CROSYl08gjHSdpsuzzNeBbzvnOg9jn76g2QozazKzppaWllErO5KSeJREUUR9CCIiB5HPZafNwIyc143A8ImBsmWazSwGVAJ7gLOBq8zs/wBVQMbMeoG1eewTAOfcXcBdAIsXLx4xNPJRUxpXH4KIyEHkEwhrgHlmNgfYBiwHrh1WZhVwPfA8cBXwpHPOAR/PFjCzvwU6nXP/FITGaPscU9VlGq0sInIwowaCcy5lZjcBjwFRYKVzboOZfQNocs6tAu4G7jWzTfiWwfLD2ecRHstBVZfG2aNTRiIiB5TXSGXn3Gpg9bB1X8t53gtcPco+/na0fY6n6rI4zW3dE/VxIiKAn+30vvvu4ytf+cohb/ud73yHFStWUFpaOg41218oRiqDn76irVtXGYnIxDrc+yGAD4Tu7on7IRuKuYzAtxD29iRJpTPEoqHJQREpsNzpry+88EKOO+44fvrTn9LX18cVV1zB17/+dbq6urjmmmtobm4mnU5z++2388EHH7B9+3bOP/986urqeOqpp8a9rqEJhOxo5faeJHXlxaOUFpFJ6dFbYedrY7vP4xfCJd884Nu5018//vjjPPTQQ7z00ks45/jsZz/LM888Q0tLCw0NDfziF78A/BxHlZWV3HHHHTz11FPU1dWNbZ0PIDQ/lQfmM9KVRiJSII8//jiPP/44Z5xxBmeeeSZvvvkmGzduZOHChTzxxBN89atf5dlnn6WysrIg9QtdC0FjEURC7CC/5CeCc47bbruNL33pS/u9t3btWlavXs1tt93GRRddxNe+9rUR9jC+QtNCqCotAjTjqYhMrNzpry+++GJWrlxJZ6efvGHbtm3s2rWL7du3U1paynXXXcfNN9/Myy+/vN+2EyGELQRdaSQiEyd3+utLLrmEa6+9lo985CMAlJeX85Of/IRNmzZxyy23EIlEKCoq4vvf/z4AK1as4JJLLmHatGkT0qlsfkDxsWHx4sWuqanpsLbtTab58O2/5JaL5/Nn588d45qJyNHqjTfe4KSTTip0NSbMSMdrZmudc4tH2zY0p4wSRVFK41F1KouIHEBoAgE0fYWIyMGEKhBqNMGdSCgdS6fGj8SRHmeoAqG6LM4eTV8hEiqJRILdu3dP+lBwzrF7924SicRh7yM0VxmBn89oS2tXoashIhOosbGR5uZmDvcGW8eSRCJBY2PjYW8fqkCoKtUpI5GwKSoqYs6cOYWuxjEhVKeMasridPSl6E9lCl0VEZGjTqgCoXpggju1EkREhgtVINQMTHCnjmURkeFCFQjVZX4+I01wJyKyv1AFQnY+I01wJyKyv3AFQqmmwBYROZBQBUKVbpIjInJAoQqEeCxCeXFM8xmJiIwgVIEAvmO5XdNXiIjsJ3SBUFMaVx+CiMgIQhcI1WVxXWUkIjKC0AWCWggiIiMLRyCs/h/w3HeBoIWgQBAR2U84AmHrC7DlOcAPTuvqT9ObTBe4UiIiR5dwBEJpHXT5udCrSv30FbrSSERkqLwCwcyWmtlbZrbJzG4d4f1iM3sweP9FM5sdrF9iZuuC5VUzuyJnmy1m9lrwXtNYHdCIyuqhuxXImeBOHcsiIkOMeoMcM4sCdwIXAs3AGjNb5Zx7PafYDUCbc26umS0HvgX8IbAeWOycS5nZNOBVM/sP51wq2O5851zrWB7QiMrqoMt/THYKbPUjiIgMlU8LYQmwyTm32TnXDzwALBtWZhlwT/D8IeACMzPnXHfOl38CKMxNTcvqINkN/d0DE9xptLKIyFD5BMJ0YGvO6+Zg3YhlggDYC9QCmNnZZrYBeA34ck5AOOBxM1trZisO9OFmtsLMmsys6bDviVpa5x+7W6nWfEYiIiPKJxBshHXDf+kfsIxz7kXn3ALgLOA2M0sE75/rnDsTuAT4MzM7b6QPd87d5Zxb7JxbXF9fn0d1R1AWBEJXy0Cn8h7dJEdEZIh8AqEZmJHzuhHYfqAyZhYDKoE9uQWcc28AXcApwevtweMu4BH8qanxURYESdduiqIRpiRi6lQWERkmn0BYA8wzszlmFgeWA6uGlVkFXB88vwp40jnngm1iAGY2C5gPbDGzMjOrCNaXARfhO6DHR2mtfwwuPa0p02hlEZHhRr3KKLhC6CbgMSAKrHTObTCzbwBNzrlVwN3AvWa2Cd8yWB5s/jHgVjNLAhngK865VjM7AXjEzLJ1uM8598uxPrgBZYN9CODvi6AWgojIUKMGAoBzbjWweti6r+U87wWuHmG7e4F7R1i/GTjtUCt72OLlEEsMXHpaUxZnV0fvhH28iMixIBwjlc2C0crBWITSOG3qVBYRGSIcgQD+tFF2tHJZkfoQRESGCVcg5IxW7kmm6enXBHciIlnhCYScU0aaz0hEZH/hCYScU0bZ+Yx02khEZFC4AiHZDf1dg9NXqIUgIjIgPIGQnc+oq5WaMj99RZvuiSAiMiA8gZCdvkIT3ImIjChEgTDYQqgsKcJMfQgiIrlCGQixaITKkiL1IYiI5AhPIJQOToEN/tJTtRBERAaFJxDiZX4+o5xLT9VCEBEZFJ5AMPMdy127AT+fkW6SIyIyKDyBAP6+CMEpo+rSItrVQhARGRCuQBgywZ3vQ3Bu+N1ARUTCKWSBUD9kgru+VIaepCa4ExGBsAVCae1+E9zpSiMRES9cgVBWD6keP59RWXa0sjqWRUQgdIEwOBYhO5/RHnUsi4gAYQuEgcFpuzWfkYjIMOEKhJEmuFMLQUQECF0g1PrHrhamlBQRMbUQRESywhUIOfdEiEaMqtK4+hBERALhCoR4GcRKhoxW1lVGIiJeuALBLBit7Oczyo5WFhGRsAUC+EDIjlYu1YynIiJZ4QuE0rqBU0a15cW0dvYVuEIiIkeH8AVCzimjaZUJWjv76UtpPiMRkbwCwcyWmtlbZrbJzG4d4f1iM3sweP9FM5sdrF9iZuuC5VUzuyLffY6bsqCF4BzTKhMA7NzbO2EfLyJytBo1EMwsCtwJXAKcDHzezE4eVuwGoM05Nxf4NvCtYP16YLFz7nRgKfCvZhbLc5/jo7QOUr3Q30VDVQkA29sVCCIi+bQQlgCbnHObnXP9wAPAsmFllgH3BM8fAi4wM3POdTvnUsH6BJC9+UA++xwf2fmMulsHWgg79vZMyEeLiBzN8gmE6cDWnNfNwboRywQBsBeoBTCzs81sA/Aa8OXg/Xz2SbD9CjNrMrOmlpaWPKo7iuz0FV2tTKv0LYQdOmUkIpJXINgI64bfZuyAZZxzLzrnFgBnAbeZWSLPfRJsf5dzbrFzbnF9fX0e1R1FzmjlkniU6tIitrerhSAikk8gNAMzcl43AtsPVMbMYkAlsCe3gHPuDaALOCXPfY6PnCmwAaZVlqiFICJCfoGwBphnZnPMLA4sB1YNK7MKuD54fhXwpHPOBdvEAMxsFjAf2JLnPsdHTh8CQENVQi0EEREgNloB51zKzG4CHgOiwErn3AYz+wbQ5JxbBdwN3Gtmm/Atg+XB5h8DbjWzJJABvuKcawUYaZ9jfGwjG5jPyAfCtMoS1mxpm5CPFhE5mo0aCADOudXA6mHrvpbzvBe4eoTt7gXuzXefE6asfjAQqhLs7UnS3Z+iNJ7XP4eIyKQUvpHK4O+LkD1lVKmxCCIiENZAyJnPSGMRRES8cAZCWT10+fmMsqOVd6iFICIhF9JACE4ZOcfUKQnMYLtaCCISciENhPpgPqNO4rEIdeXFuvRUREIvnIGQM1oZoKEyocFpIhJ64QyEgcFp2fsilKiFICKhF+5ACK40aqjy01c4N+J0SiIioRDOQBh+yqgqQXd/mn09qYNsJCIyuYUzEEaY4A50pZGIhFs4AyFeBkWlg30IVRqcJiISzkCAYLSypq8QEckKbyCUDU5fUV9RTCxiaiGISKiFOxCCCe6iEWPqlISmrxCRUAtvIOScMgI/yZ06lUUkzMIbCGVBIARjD6ZV6VaaIhJu4Q6EdB/0dwKD01docJqIhFV4A6F0+FiEBP2pDLu7+gtYKRGRwglvIJTV+8eu7FgE3RdBRMItxIFQ6x+z8xlptLKIhFyIAyFoIQSXng6MVtaspyISUuENhGET3NWWxYnHIrrSSERCK7yBEC/18xkFgWBmwVgEBYKIhFN4AwGGjFYGf6WRThmJSFiFOxBKB+czAt+xrDuniUhYhTsQyoZNX1GV4IOOPtIZDU4TkfAJdyCUHwcdOwdeTqssIZ1x7OpQP4KIhE+4A6F2LnTtgp52wN9KE3RfBBEJp7wCwcyWmtlbZrbJzG4d4f1iM3sweP9FM5sdrL/QzNaa2WvB46dytnk62Oe6YDlurA4qb3Xz/WPr28DgrTR1XwQRCaNRA8HMosCdwCXAycDnzezkYcVuANqcc3OBbwPfCta3Ap9xzi0ErgfuHbbdF5xzpwfLriM4jsNTHwRCy1vA4GhlTV8hImGUTwthCbDJObfZOdcPPAAsG1ZmGXBP8Pwh4AIzM+fcK8657cH6DUDCzIrHouJjomoWROPQ6gNhSkmM0nhU01eISCjlEwjTga05r5uDdSOWcc6lgL1A7bAyVwKvOOf6ctb9MDhddLuZ2SHVfCxEY74focWfMsoOTlMLQUTCKJ9AGOmLevh1mQctY2YL8KeRvpTz/heCU0kfD5Y/GvHDzVaYWZOZNbW0tIxU5MjUnTjQQgBoqCpRH4KIhFI+gdAMzMh53QhsP1AZM4sBlcCe4HUj8AjwRefcO9kNnHPbgscO4D78qan9OOfucs4tds4trq+vz+eYDk39fGh7D5I+BBoqSzR9hYiEUj6BsAaYZ2ZzzCwOLAdWDSuzCt9pDHAV8KRzzplZFfAL4Dbn3HPZwmYWM7O64HkRcBmw/sgO5TDVnQg42L0J8IPTWjv76E9lClIdEZFCGTUQgj6Bm4DHgDeAnzrnNpjZN8zss0Gxu4FaM9sE/BWQvTT1JmAucPuwy0uLgcfM7PfAOmAb8IOxPLC8jXClkXPwwT61EkQkXGL5FHLOrQZWD1v3tZznvcDVI2z398DfH2C3i/Kv5jiqnQvY4FiEgcFpPcyoKS1gxUREJla4RyoDFJVA9ayBFsLg4DS1EEQkXBQIAPUfHmghDExfoSuNRCRkFAjgO5Z3b4J0itJ4jMqSIo1FEJHQUSCA71hO90P7e0Bwoxy1EEQkZBQIMDjJXfZKo6oSzXgqIqGjQACoP9E/tmY7ltVCEJHwUSAAJCqh/PiBOY0aqkpo607S3Z8qcMVERCaOAiGrfnBOowUNUwD47cbWg20hIjKpKBCy6ub7FoJzfGxuHXXlcX728rZC10pEZMIoELLq50N/B3TsIBaNsOz06fz6zQ9o7+4vdM1ERCaEAiGrLuhYDq40uuKM6STTjv/4/Y4CVkpEZOIoELLqh95feUHDFOZPreBnLzcXsFIiIhNHgZBVPhWKKwdaCGbG586czivvt7O5pbPAlRMRGX8KhCyz4EqjtwdWXX7GdCIGj7yizmURmfwUCLnq5g+0EACmTklw7tw6HnllG5nM8LuGiohMLgqEXPUnQtcu6GkbWHXlmY00t/WwZsueAlZMRGT8KRByDcxpNHja6KIFUymLRzUmQUQmPQVCrmFzGgGUxmMsPWUav3htB73JdIEqJiIy/hQIuapmQbR4SD8CwJVnTqezL8Xjr39QoIqJiIw/BUKuSBTq5g250gjgnBNqaahMaEyCiExqCoTh6k7cr4UQiRiXnzGdZ95uYVeH7pMgIpOTAmG4+vnQ/j4kh94P4XNnTifjYNW67QWqmIjI+FIgDFd3IuCgdeOQ1XOPq+C0xkpdbSQik5YCYbhhcxrl+tyZjby+Yx+/UueyiExCCoThaueCRfbrRwA/lcWJU8u58cdN/O/Vb9CfyhSggiIi40OBMFysGKpnDxmLkFVZUsTP/+xjfOHsmfzrM5u56l9+x7utXRNfRxGRcaBAGEn27mkjKIlH+YcrFvIv1y3ivd3dXPa9Z3U5qohMCgqEkdSfCLs3QerAd0tbesrxPPoXH2fB9Er+6qev8t8eeIV9vckJrKSIyNjKKxDMbKmZvWVmm8zs1hHeLzazB4P3XzSz2cH6C81srZm9Fjx+KmebRcH6TWb2PTOzsTqoIzb745BJwn/+JbgDz3LaUFXC/Teew3+/8ET+4/c7uPCO3/DL9TtwB9lGRORoNWogmFkUuBO4BDgZ+LyZnTys2A1Am3NuLvBt4FvB+lbgM865hcD1wL0523wfWAHMC5alR3AcY2vehfCJr8K6n8Cvv3HQotGI8ecXzONnf/pRasuK+fJPXubGH69le3vPQbcTETna5NNCWAJscs5tds71Aw8Ay4aVWQbcEzx/CLjAzMw594pzLjuSawOQCFoT04Apzrnnnf85/WPg8iM+mrH0ydtg0R/Db++AF74/avHTZlSx6qZz+etLP8xzm1r5gzt+w92/fZe07qMgIseIfAJhOrA153VzsG7EMs65FLAXqB1W5krgFedcX1A+tyd2pH0Wlhl8+g748GXwy1vhtYdG3SQWjbDivA/x+F+ex5I5Nfzdf77O5Xc+x/pteyegwiIiRyafQBjp3P7wn70HLWNmC/Cnkb50CPvMbrvCzJrMrKmlpSWP6o6hSBSuvBtmnQuPfBneeSqvzWbUlPLDPz6Lf7r2DHbu62XZnc/xv1a/QXd/apwrLCJy+PIJhGZgRs7rRmD4hD4DZcwsBlQCe4LXjcAjwBedc+/klG8cZZ8AOOfucs4tds4trq+vz6O6Y6woAcvv81NaPHgdbH8lr83MjMtObeCJv/oE1yyewV3PbObi7zzDM29PcKiJiOQpn0BYA8wzszlmFgeWA6uGlVmF7zQGuAp40jnnzKwK+AVwm3PuuWxh59wOoMPMzgmuLvoi8PMjPJbxU1IF1z0MJTXwk6ug6YfQnd8tNStLivjfn1vIgyvOoSga4YsrX+IvH1zH7s6+ca60iMihsXwukTSzS4HvAFFgpXPuH8zsG0CTc26VmSXwVxCdgW8ZLHfObTaz/wncBuTOFHeRc26XmS0GfgSUAI8Cf+5GqczixYtdU1PTIR/kmGnd5FsJLW9ApAjmXgALr4b5l0C8bNTNe5Np/vnpd/j+05soL47x15eexOfObCQaOXquuBWRycfM1jrnFo9a7li6Zr7ggQB+XMLO38Nr/w/W/wz2bYOiUph/KSy5EWaeM+ou3v6gg9t+9hpr32tj/tQKbr54Pn9w0nEcTUMxRGTyUCBMhEwG3n/eh8Pr/w49bXDCJ/0lq6MEQybjWL1+B3c8/jabW7s4Y2YVt1w8n49+qG5Cqi4i4aFAmGj9XdC0Ep77LnS15B0MqXSGh9Y2891fb2TH3l4+Pq+OWy6ez6mNVRNSbRGZ/BQIhTJSMJz7FzDnE/4y1gPoTab5yQvvcedTm2jrTrJoVjXLz5rBZac2UBI/8HYiIqNRIBTa8GCoaIBTr4HTPg/HffiAm3X0Jnngpa3cv+Z9Nrd0UZGIccUZ01l+1kxObpgygQcgIpOFAuFokeyBtx6FVx+ATU+AS8O00+G05XDKVVA+8tgK5xwvvbuH+196n9Xrd9KfynDajCpuOn+uOqBF5JAoEI5Gnbtg/cPw6v2w41WIxGDeRXD6tTDvYojFR9ysvbufn728jR8/v4Utu7tZMruG2y79MGfMrJ7Y+ovIMUmBcLT74HUfDL//KXTu9IPeFl7tw2HaaX4upWGS6QwPrtnKd57YSGtnH5cuPJ5bLv4wc+pGHwMhIuGlQDhWpFOw+SlYdx+8+QtI98HUU+CcP/UBESveb5OuvhQ/eHYzdz2zmf5Uhs8vmcl/vWAe9RX7lxURUSAci3raYMMjsGYlfPAaVEzzwbDojyFRuV/xlo4+vvvrt7n/pa0URY0/OmcWK877kIJBRIZQIBzLnIN3noTffQ82Pw3xClj8Jz4cpjTsV/zd1i7+8cmN/Psr24jHInzxI7NZcd4J1JUrGEREgTB5bF/ng2HDI2BROOkzvsUw57z9+hk2t3Tyj09u4ufrtlEci/LFj8ziRgWDSOgpECabti3wwr/4jujedqg5wQfDadfud+nqpl2d/OOTG1n16nYSsShfOHsmK847geOmJApSdREpLAXCZJXsgddXwdofwfu/87OunnQZfOQmaBz633vTrg7ufOodfr5uG7FohOVnzeDLn/gQDVUlham7iBSEAiEMWt6CtffAq/f5DumTPgsX/A3UzR1SbEtrF99/+h0efrkZM7hqUSN/+om5zKwtLVDFRWQiKRDCpK8Tnv8neO57kOqFRdfDJ26FiqlDijW3dfOvv9nMg01bSaUzXLzgeG742BwWzarWyGeRSUyBEEadu+A3/wfW/hCicX8a6aN/DomhcyB9sK+XH/1uC/e9+D57e5Kc2ljJfzl3DpcunEY8ls9N9ETkWKJACLPd78CTf+evTCoq830MC6/xM69GYwPFuvtT/Ozlbax87l02t3QxdUoxX/zIbK5dMpPqspGn0RCRY48CQWDby77z+fV/h969UFbvJ9Q79RpoOGPgstVMxvGbjS2s/O27PLuxlZKiKFcvbuSGj81hVq2mxRA51ikQZFCqDzY+Dr9/EN5+DNL9UDcfzv6Sn447Pti5/NbODv7t2c38fN12kpkMF598PDeeN4dFs2oKeAAiciQUCDKynjZ4/efQ9EPYsQ5KqmHRn8CSFTBl2kCxXft6uef5LfzkBd/PcMbMKq47exaXLDye0njswPsXkaOOAkEOzjl/P+jn7/ST6kVicMrn4JyvQMPpA8W6+1M8tLaZHz63hXdbuyiLR7lk4TSuWtTIktk1RCK6OknkaKdAkPzteRde/Fd45V7o74TGs2DxDbDgCijyo5udczS918ZDTc384rUddPalaKwu4cozG1l2egMn1JcX+CBE5EAUCHLoevfCK//X3/pz90Z/OumM6/wppdoPDRTr6U/z2IadPLS2mefeacU5mD+1gqWnHM+lC6dx4tRyjWsQOYooEOTwOQfvPgNNd/vTSZkUfOhTsOBzMPcPhvQ17Njbw6Ov7eSX63ey5r09OAcn1JWx9JTj+eT84zi5YQrlxepzECkkBYKMjY6d8PKP/bJ3q193/Kkw70J/+8/piwfGNuzq6OXxDR/wy/U7eX7zbtIZ/7c1u7aUkxumcPK0KSxoqGRBwxRNtCcygRQIMracg12v+8tXN/4K3n8BXBoSVb7VMP8SmHuBP80EtHX18/L7bby+fR+v7/DLe7u7B3Y3o6aEs2bXsGR2DYtn1/Ch+jKdZhIZJwoEGV897f7Wnxt/5UOiq8Xfr2HWR+HEpT4gcvodADp6k7y5s4NXt7azZssemra0sburH4CasjhnzqxmelWCuvJi6iqKqS2LU1dRTH15McdNKaY4Fi3EkYoc8xQIMnEyGdi2Ft5+FN76Jeza4NdPaYT6+X6pO3HwsawO8FcubW7tomnLHl56t41Xm9vZta+Xfb2pET+mvqKYhsoEDVUlNFSVMK0ywfGVQYCU++CYUhJTS0NkmDENBDNT3lmOAAAMUklEQVRbCnwXiAL/5pz75rD3i4EfA4uA3cAfOue2mFkt8BBwFvAj59xNOds8DUwDeoJVFznndh2sHgqEY0Tbe35EdPNLforu1o2Q6hl8v7TWj5Sunw/1H4b6E/1jxTQwoy+VZndnP62dfX7p6GfH3l62t/ewfW+Pf2zvpSeZ3u+j49EIdeVxKkvjFEWNomiEWMSIxwYfy4pjlBfHBh/jUUqLYxTHIhTHohTHIsSzSzRCV3+K9u4ke7r6ae/up607SVt3P32pDEURIxrx+45GjVjESBRFqS6NU1sWp6YsTk25f15ZUkR/KkNvMkNPMk1vsPSlMsRjEUrjUUrjUUriMUqLopTEo8QOMM4jYnZEY0Ccc3T3p+nqS4FBUSRCLPj3KopGiB7F40syGUfaOdIZv6SCvqrSeJSiqCZnHEm+gTDq5R9mFgXuBC4EmoE1ZrbKOfd6TrEbgDbn3FwzWw58C/hDoBe4HTglWIb7gnNO3/CTTfUsOHuFX8C3IPZuhda3g4B4C1re9pPv9bYPbhevgMrpFFccT0PFNBoqjoeKBqg4HuprfP9EohFKqnCxEtp7Uuzq6BsIjpaOPlqCANnbkySVyZBKO/rTGbr6UiTTjr5Umq6+NF39qYF1h6osHqWqNE5xUcR/IaWzX0wZUhn/RdufyozRP+aBxWMRErEIiaJosPgQi5hhZkQMDB8eDujqS9HRm6KjN0lnX4rMQQ7dgpCIRiwn7Hzw5WbF8F1EzIhG/BIxgkcjlrN99nk2dBw+oJwDh39Mpn1odven6e1P05P0S18qw8F+w8ajEcqKo5TGfdiXxH3A+6ALAi8WoSji/01SGUcqnSGdcSSD/44ORyziy8dygtLXPUI86h+z+4xGzNfdORyQcY6M84/ODQaYc9n3HIb/94kE/z7RiA3cEfdA2/ztZxYQG+fAy+d6wCXAJufcZgAzewBYBuQGwjLgb4PnDwH/ZGbmnOsCfmtmQ+/YIuESifiQqJ7lr07Kcs5P2d361mBLomO7v7Lp3Wehc6e/5HUEFimiuqSa6tIa5pfV+1ZHWZ2fwK+2FkprfMAUV0BxOcTLg+cVEBu8x/RAQPSl6EtlSO/bSdHOlyne+TJlLeso27MeLEq6/HisYhqxqgaildN9SJVP9Z9bWuMfS6ohEvW/vnt62duylc6WrfS1NZNq24braae/dCrJ8kZSUxpxlTNJJEqIxyL0pzJ096fpTqbp6+km3d1GpruNpMXpLqolFR16VVYq4+hNpelLZgZaGr3JDH2pdPAFC2RSVKb2UJ1uoTLTRrw4RtGUBMXFCeLxBIlEgnhxAheJkcxE6CdKf8bod1H6M5HgF3iadDqDy6RIpTO4dMZ/UVmEjEXJEMVFImSIkrQ4SaLBl1nwpZbzaz775ZvKOHqSaVLpIDRzwsvMMHzYTUkUkYhHKSkKluDLPRtSkexj8E3a05+mK2j1ZAM/G87d/T78k+lMsDjM8F/ywZd+9gsfIJX25bM/KlIZN7BdKpMhmcqQDNblBlTEgtab+QOKBseWbdFFjIFTmumM/6LPZHIChJG3iZjxPz99MuPdjZZPIEwHtua8bgbOPlAZ51zKzPYCtUDrKPv+oZmlgYeBv3fHUoeGHDkzfxOfiqkw57z9389koHs3dOyAnj1+Hqaedt+q6GkPXu+Brt3wwQbobvXrRhMt9veISFRSXDyF4kQlNbFiv4/spbWRGExdAKddDRhFHTt8Pd55A7p2gRupBWBQUoVFYpR1tVK23+/nEVRMgykNkOoPjqcNkl37l4tXQPlxfimrh+IpgPPf/BEH8WBJ9sC+7X7p3HmAeo6jkmooC+pZPjUIzWro6/D/nbqDpS/4b5WohMoZUNmYs8yAolJIdfiJGZM9/sZPqV5/vIlKKKnyV7glKv1jcbl/z2X81W8uE/zUTvnP6d499PO79wTNoBKIJfznFZX4JRIbmAnYC55bxP+YiBZBtCR4HidDBEt2Yn0dfnBn717o2+ePOZMe/O+Ula1nJuXrmkn5v/VMyk80WTUTqmdD1Sz/WFI9rD7jJ59AGKkmw//S8ykz3Becc9vMrAIfCH+E74cYumOzFcAKgJkzZ45eW5k8IhEor/dLvtJJ/z97zx5/J7n+Dv/Y1+Gn5ejbB737gse9g887d/l7Up/9Zf847TT/5TDiZ6Sg8wN/ZVX37sEvnO49/jHdH3zRT/OnvLKPiUr/Jd3+fs7yHuzdBuUlMO1U/z9/SVVweqzKfwl2fgCdLYOf2fIm9HcBFnxRBD+vMf8lNaUBPnS+f5zSAFOm+xDJ/vuk+4MleJ5JDV3SyaBlFuzfIkMXnP+iy6QGv9gyKUj2+rDsDJZta/1jssvfsKm0DspqfWuq6gx/jL17YW+zbxF2bJ+4ACsq88eW7D7izzzgSZxIzN/zHAb/O2WfW9T/fUdiwfOYf93Xsf+PmniFb13/yaP73exqrOUTCM3AjJzXjcD2A5RpNrMYUAnsOdhOnXPbgscOM7sPf2pqv0Bwzt0F3AW+UzmP+kqYRYsGWx3j9hkxqJzul0OV/RU866NjX6+jVarPB8Jov3LTKd8K27vVB2EsEfx6Lxl8DoO/wgeWdv9Fmhtakejg85Lq4NRezhLM0YVzPhSTPcHSPfQ05ZBf9ml/LOkkpPt8qy4bqMXlUFzpv7CLp/jHWOLwftn37vM/FNreG3zct82f7hxn+QTCGmCemc0BtgHLgWuHlVkFXA88D1wFPHmw0z9BaFQ551rNrAi4DHjiMOovIke7nD6bg4rGoGqGXw4mZ+qUI2ZBqypW7FtmR4PEFDh+oV8m2KiBEPQJ3AQ8hr/sdKVzboOZfQNocs6tAu4G7jWzTfiWwfLs9ma2BZgCxM3scuAi4D3gsSAMovgw+MGYHpmIiBwSDUwTEZnk8h2HoFEcIiICKBBERCSgQBAREUCBICIiAQWCiIgACgQREQkcU5edmlkLfgzD4ahj9LmVJiMdd7jouMMl3+Oe5ZwbdQ6YYyoQjoSZNeVzHe5ko+MOFx13uIz1ceuUkYiIAAoEEREJhCkQ7ip0BQpExx0uOu5wGdPjDk0fgoiIHFyYWggiInIQkz4QzGypmb1lZpvM7NZC12c8mdlKM9tlZutz1tWY2a/MbGPwWF3IOo4HM5thZk+Z2RtmtsHM/iJYP6mP3cwSZvaSmb0aHPfXg/VzzOzF4LgfNLN4oes6HswsamavmNl/Bq8n/XGb2RYze83M1plZU7BuzP7OJ3UgmFkUuBO4BDgZ+LyZnVzYWo2rHwFLh627Ffi1c24e8Ovg9WSTAv67c+4k4Bzgz4L/zpP92PuATznnTgNOB5aa2TnAt4BvB8fdBtxQwDqOp78A3sh5HZbjPt85d3rO5aZj9nc+qQMBf1vOTc65zc65fuABYFmB6zRunHPPsP+tS5cB9wTP7wEun9BKTQDn3A7n3MvB8w78l8R0JvmxO68zeFkULA74FPBQsH7SHTeAmTUCnwb+LXhthOC4D2DM/s4neyBMB7bmvG4O1oXJVOfcDvBfnMBxBa7PuDKz2cAZwIuE4NiD0ybrgF3Ar4B3gHbnXPbGwJP1b/47wP8AMsHrWsJx3A543MzWmtmKYN2Y/Z3nc0/lY9lId7jWZVWTlJmVAw8D/805t88O5wbnxxjnXBo43cyqgEeAk0YqNrG1Gl9mdhmwyzm31sw+mV09QtFJddyBc51z283sOOBXZvbmWO58srcQmoHcO3Y3AtsLVJdC+cDMpgEEj7sKXJ9xEdyf+2Hg/zrnfhasDsWxAzjn2oGn8X0oVWaW/bE3Gf/mzwU+G9yv/QH8qaLvMPmPG+fc9uBxF/4HwBLG8O98sgfCGmBecPVBHFgOrCpwnSbaKuD64Pn1wM8LWJdxEZw/vht4wzl3R85bk/rYzaw+aBlgZiXAH+D7T54CrgqKTbrjds7d5pxrdM7Nxv8//aRz7gtM8uM2szIzq8g+By4C1jOGf+eTfmCamV2K//UQBVY65/6hwFUaN2Z2P/BJ/AyIHwB/A/w78FNgJvA+cLVzbnjH8zHNzD4GPAu8xuA55b/G9yNM2mM3s1PxnYhR/I+7nzrnvmFmJ+B/OdcArwDXOef6ClfT8ROcMrrZOXfZZD/u4PgeCV7GgPucc/9gZrWM0d/5pA8EERHJz2Q/ZSQiInlSIIiICKBAEBGRgAJBREQABYKIiAQUCCIiAigQREQkoEAQEREA/j8edumukZ5VNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401, 1)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a prediction\n",
    "predictions = model.predict(X_validation)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validation = Y_validation.reshape((len(Y_validation), 1))\n",
    "#Y_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004356925211400366\n",
      "0.8550426566147347\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "print(mean_squared_error(Y_validation, predictions))\n",
    "print(r2_score(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2005, 12)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-04    0.076488\n",
       "2011-01-05    0.090435\n",
       "2011-01-06    0.085373\n",
       "2011-01-07    0.072184\n",
       "2011-01-10    0.079145\n",
       "2011-01-11    0.069411\n",
       "2011-01-12    0.045107\n",
       "2011-01-13    0.036491\n",
       "2011-01-14    0.048756\n",
       "2011-01-18    0.029124\n",
       "2011-01-19    0.013250\n",
       "2011-01-20    0.017302\n",
       "2011-01-21   -0.001753\n",
       "2011-01-25   -0.029161\n",
       "2011-01-26   -0.028655\n",
       "2011-01-27   -0.045138\n",
       "2011-01-28   -0.076604\n",
       "2011-02-01   -0.067663\n",
       "2011-02-02   -0.070815\n",
       "2011-02-03   -0.071262\n",
       "2011-02-04   -0.099111\n",
       "2011-02-07   -0.095556\n",
       "2011-02-08   -0.128344\n",
       "2011-02-09   -0.146706\n",
       "2011-02-10   -0.128908\n",
       "2011-02-11   -0.107621\n",
       "2011-02-14   -0.119743\n",
       "2011-02-16   -0.132146\n",
       "2011-02-17   -0.106909\n",
       "2011-02-18   -0.100036\n",
       "                ...   \n",
       "2019-04-30   -0.081137\n",
       "2019-05-01   -0.061231\n",
       "2019-05-02   -0.090464\n",
       "2019-05-03   -0.092045\n",
       "2019-05-06   -0.121153\n",
       "2019-05-07   -0.096593\n",
       "2019-05-08   -0.053747\n",
       "2019-05-09   -0.017898\n",
       "2019-05-10    0.002837\n",
       "2019-05-13   -0.009528\n",
       "2019-05-14    0.031708\n",
       "2019-05-15    0.022158\n",
       "2019-05-16    0.017079\n",
       "2019-05-17   -0.015640\n",
       "2019-05-21    0.023669\n",
       "2019-05-22    0.030574\n",
       "2019-05-23    0.027493\n",
       "2019-05-24    0.051296\n",
       "2019-05-28    0.037810\n",
       "2019-05-29    0.058953\n",
       "2019-05-30    0.063831\n",
       "2019-05-31    0.068211\n",
       "2019-06-03    0.095841\n",
       "2019-06-04    0.133083\n",
       "2019-06-05    0.117618\n",
       "2019-06-06    0.111594\n",
       "2019-06-07    0.093133\n",
       "2019-06-10    0.050847\n",
       "2019-06-11    0.029259\n",
       "2019-06-12    0.041779\n",
       "Name: 1Y(t-1), Length: 2005, dtype: float64"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed.iloc[:,-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
