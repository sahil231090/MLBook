{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83708667-4fdc-1563-7b3a-06b6575d2865"
   },
   "source": [
    "\n",
    "\n",
    "# Supervised Machine Learning- Classification and Regression Template\n",
    "How do you work through a predictive modeling- Classification or Regression based Machine learning problem end-to-end? \n",
    "In this jupyter note you will work through a case study classication predictive modeling problem in Python\n",
    "including each step of the applied machine learning process. \n",
    "However, this notebook is applicable for Regression based case study as well. The Models, Grid Search and Evaluation Metrics will need to change for the regression based case study.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. Introduction](#0)\n",
    "* [2. Getting Started - Load Libraries and Dataset](#1)\n",
    "    * [2.1. Load Libraries](#1.1)    \n",
    "    * [2.2. Load Dataset](#1.2)\n",
    "* [3. Exploratory Data Analysis](#2)\n",
    "    * [3.1 Descriptive Statistics](#2.1)    \n",
    "    * [3.2. Data Visualisation](#2.2)\n",
    "* [4. Data Preparation](#3)\n",
    "    * [4.1 Data Cleaning](#3.1)\n",
    "    * [4.2.Handling Categorical Data](#3.2)\n",
    "    * [4.3.Feature Selection](#3.3)\n",
    "    * [4.3.Data Transformation](#3.4) \n",
    "        * [4.3.1 Rescaling ](#3.4.1)\n",
    "        * [4.3.2 Standardization](#3.4.2)\n",
    "        * [4.3.3 Normalization](#3.4.3)    \n",
    "* [5.Evaluate Algorithms and Models](#4)        \n",
    "    * [5.1. Train/Test Split](#4.1)\n",
    "    * [5.2. Test Options and Evaluation Metrics](#4.2)\n",
    "    * [5.3. Compare Models and Algorithms](#4.3)\n",
    "        * [5.3.1 Common Classification Models](#4.3.1)\n",
    "        * [5.3.2 Ensemble Models](#4.3.2)\n",
    "        * [5.3.3 Deep Learning Models](#4.3.3)    \n",
    "* [6. Model Tuning and Grid Search](#5)  \n",
    "* [7. Finalize the Model](#6)  \n",
    "    * [7.1. Results on test dataset](#6.1)\n",
    "    * [7.1. Variable Intuition/Feature Selection](#6.2) \n",
    "    * [7.3. Save model for later use](#6.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal in this jupyter notebook is to under the following\n",
    "- How to work through a predictive modeling problem end-to-end. This notebook is applicable both for regression and classification problems.\n",
    "- How to use data transforms to improve model performance.\n",
    "- How to use algorithm tuning to improve model performance.\n",
    "- How to use ensemble methods and tuning of ensemble methods to improve model performance.\n",
    "- How to use deep Learning methods.\n",
    "\n",
    "The data is a subset of the German Default data (https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data) with the following attributes. Age, Sex, Job, Housing, SavingAccounts, CheckingAccount, CreditAmount, Duration, Purpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "# 2. Getting Started- Loading the data and python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Loading the python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "5d8fee34-f454-2642-8b06-ed719f0317e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv, set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "#Libraries for Deep Learning Models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "#Libraries for Saving the Model\n",
    "from pickle import dump\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "## 2.2. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "787e35f7-bf9e-0969-8d13-a54fa87f3519"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'german_credit_data.csv' does not exist: b'german_credit_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c9339c32f2f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'german_credit_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'german_credit_data.csv' does not exist: b'german_credit_data.csv'"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = read_csv('german_credit_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "df6a4523-b385-69ee-c933-592826d81431"
   },
   "source": [
    "<a id='2'></a>\n",
    "# 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "## 3.1. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "52f85dc2-0f91-3c50-400e-ddc38bea966b"
   },
   "outputs": [],
   "source": [
    "# shape\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peek at data\n",
    "set_option('display.width', 100)\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f36dd804-0c16-f0c9-05c9-d22b85a79e75"
   },
   "outputs": [],
   "source": [
    "# types\n",
    "set_option('display.max_rows', 500)\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7bffeec0-5bbc-fffb-18f2-3da56b862ca3"
   },
   "outputs": [],
   "source": [
    "# describe data\n",
    "set_option('precision', 3)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "565b36d1-0abc-e91c-47f5-c3153d54e265"
   },
   "outputs": [],
   "source": [
    "# class distribution\n",
    "dataset.groupby('Housing').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2'></a>\n",
    "## 3.2. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "16d50177-f93e-9d26-af7a-313d7ebe9fcf"
   },
   "outputs": [],
   "source": [
    "# histograms\n",
    "dataset.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1, figsize=(12,12))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ca420570-fce1-e2ff-8511-50691e099d69"
   },
   "outputs": [],
   "source": [
    "# density\n",
    "dataset.plot(kind='density', subplots=True, layout=(3,3), sharex=False, legend=True, fontsize=1, figsize=(15,15))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box and Whisker Plots\n",
    "dataset.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False, figsize=(15,15))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation\n",
    "correlation = dataset.corr()\n",
    "pyplot.figure(figsize=(15,15))\n",
    "pyplot.title('Correlation Matrix')\n",
    "sns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='cubehelix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot Matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "pyplot.figure(figsize=(15,15))\n",
    "scatter_matrix(dataset,figsize=(12,12))\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 4. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.1'></a>\n",
    "## 4.1. Data Cleaning\n",
    "Check for the NAs in the rows, either drop them or fill them with the mean of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for any null values and removing the null values'''\n",
    "print('Null Values =',dataset.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that there are null values drop the rown contianing the null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows containing NA\n",
    "dataset.dropna(axis=0)\n",
    "# Fill na with 0\n",
    "#dataset.fillna('0')\n",
    "\n",
    "#Filling the NAs with the mean of the column.\n",
    "#dataset['col'] = dataset['col'].fillna(dataset['col'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.2'></a>\n",
    "## 4.2. Handling Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ed5921628b55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlb_make\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Sex_Code\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlb_make\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Sex\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Housing_Code\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlb_make\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Housing\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"SavingAccount_Code\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlb_make\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"SavingAccounts\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "dataset[\"Sex_Code\"] = lb_make.fit_transform(dataset[\"Sex\"])\n",
    "dataset[\"Housing_Code\"] = lb_make.fit_transform(dataset[\"Housing\"])\n",
    "dataset[\"SavingAccount_Code\"] = lb_make.fit_transform(dataset[\"SavingAccounts\"].fillna('0'))\n",
    "dataset[\"CheckingAccount_Code\"] = lb_make.fit_transform(dataset[\"CheckingAccount\"].fillna('0'))\n",
    "dataset[\"Purpose_Code\"] = lb_make.fit_transform(dataset[\"Purpose\"])\n",
    "dataset[\"Risk_Code\"] = lb_make.fit_transform(dataset[\"Risk\"])\n",
    "dataset[[\"Sex\", \"Sex_Code\",\"Housing\",\"Housing_Code\",\"Risk_Code\",\"Risk\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the old features\n",
    "dataset.drop(['Sex','Housing','SavingAccounts','CheckingAccount','Purpose','Risk'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Job</th>\n",
       "      <th>CreditAmount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Sex_Code</th>\n",
       "      <th>Housing_Code</th>\n",
       "      <th>c</th>\n",
       "      <th>CheckingAccount_Code</th>\n",
       "      <th>Purpose_Code</th>\n",
       "      <th>Risk_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>5951</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2096</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>7882</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>4870</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Job  CreditAmount  Duration  Sex_Code  Housing_Code  c  CheckingAccount_Code  \\\n",
       "0   67    2          1169         6         1             1  0                     1   \n",
       "1   22    2          5951        48         0             1  1                     2   \n",
       "2   49    1          2096        12         1             1  1                     0   \n",
       "3   45    2          7882        42         1             0  1                     1   \n",
       "4   53    2          4870        24         1             0  1                     1   \n",
       "\n",
       "   Purpose_Code  Risk_Code  \n",
       "0             5          1  \n",
       "1             5          0  \n",
       "2             3          1  \n",
       "3             4          1  \n",
       "4             1          0  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.3'></a>\n",
    "## 4.3. Feature Selection\n",
    "Statistical tests can be used to select those features that have the strongest relationship with the output variable.The scikit-learn library provides the SelectKBest class that can be used with a suite of different statistical tests to select a specific number of features.\n",
    "The example below uses the chi-squared (chiÂ²) statistical test for non-negative features to select 10 of the best features from the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=5, score_func=<function chi2 at 0x0000021E7FEC2598>)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=5)\n",
    "bestfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Specs      Score\n",
      "2          CreditAmount  58262.490\n",
      "3              Duration    321.031\n",
      "7  CheckingAccount_Code     35.759\n",
      "0                   Age     30.200\n",
      "8          Purpose_Code      5.078\n",
      "4              Sex_Code      1.767\n",
      "6    SavingAccount_Code      0.900\n",
      "1                   Job      0.240\n",
      "5          Housing_Code      0.098\n"
     ]
    }
   ],
   "source": [
    "Y= dataset[\"Risk_Code\"]\n",
    "X = dataset.loc[:, dataset.columns != 'Risk_Code']\n",
    "fit = bestfeatures.fit(X,Y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seem from the numbers above Credit Amount is the most important feature followed by duration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.4'></a>\n",
    "## 4.4. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.4.1'></a>\n",
    "### 4.4.1. Rescale Data\n",
    "When your data is comprised of attributes with varying scales, many machine learning algorithms\n",
    "can benefit from rescaling the attributes to all have the same scale. Often this is referred to\n",
    "as normalization and attributes are often rescaled into the range between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.029</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.054</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.536</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.464</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.607</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3    4    5     6      7      8\n",
       "0  0.857  0.667  0.051  0.029  1.0  0.5  0.00  0.333  0.714\n",
       "1  0.054  0.667  0.314  0.647  0.0  0.5  0.25  0.667  0.714\n",
       "2  0.536  0.333  0.102  0.118  1.0  0.5  0.25  0.000  0.429\n",
       "3  0.464  0.667  0.420  0.559  1.0  0.0  0.25  0.333  0.571\n",
       "4  0.607  0.667  0.254  0.294  1.0  0.0  0.25  0.333  0.143"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = dataset.loc[:, dataset.columns != 'Risk_Code']\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX = pd.DataFrame(scaler.fit_transform(X))\n",
    "# summarize transformed data\n",
    "rescaledX.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.4.2'></a>\n",
    "### 4.4.2. Standardize Data\n",
    "Standardization is a useful technique to transform attributes with a Gaussian distribution and\n",
    "differing means and standard deviations to a standard Gaussian distribution with a mean of\n",
    "0 and a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.766</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>-1.236</td>\n",
       "      <td>0.670</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-1.231</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>1.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.191</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.950</td>\n",
       "      <td>2.248</td>\n",
       "      <td>-1.492</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>1.044</td>\n",
       "      <td>1.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.183</td>\n",
       "      <td>-1.384</td>\n",
       "      <td>-0.417</td>\n",
       "      <td>-0.739</td>\n",
       "      <td>0.670</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-1.046</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.832</td>\n",
       "      <td>0.147</td>\n",
       "      <td>1.634</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.670</td>\n",
       "      <td>-2.017</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.535</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.670</td>\n",
       "      <td>-2.017</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8\n",
       "0  2.766  0.147 -0.745 -1.236  0.670 -0.134 -1.231 -0.001  1.073\n",
       "1 -1.191  0.147  0.950  2.248 -1.492 -0.134 -0.197  1.044  1.073\n",
       "2  1.183 -1.384 -0.417 -0.739  0.670 -0.134 -0.197 -1.046  0.062\n",
       "3  0.832  0.147  1.634  1.750  0.670 -2.017 -0.197 -0.001  0.567\n",
       "4  1.535  0.147  0.567  0.257  0.670 -2.017 -0.197 -0.001 -0.950"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = dataset.loc[:, dataset.columns != 'Risk_Code']\n",
    "scaler = StandardScaler().fit(X)\n",
    "StandardisedX = pd.DataFrame(scaler.fit_transform(X))\n",
    "# summarize transformed data\n",
    "StandardisedX.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.4.3'></a>\n",
    "### 4.4.1. Normalize Data\n",
    "Normalizing in scikit-learn refers to rescaling each observation (row) to have a length of 1 (called\n",
    "a unit norm or a vector with the length of 1 in linear algebra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057</td>\n",
       "      <td>1.708e-03</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.005</td>\n",
       "      <td>8.540e-04</td>\n",
       "      <td>8.540e-04</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>8.540e-04</td>\n",
       "      <td>4.270e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004</td>\n",
       "      <td>3.361e-04</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>1.680e-04</td>\n",
       "      <td>1.680e-04</td>\n",
       "      <td>3.361e-04</td>\n",
       "      <td>8.402e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023</td>\n",
       "      <td>4.770e-04</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>4.770e-04</td>\n",
       "      <td>4.770e-04</td>\n",
       "      <td>4.770e-04</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>1.431e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006</td>\n",
       "      <td>2.537e-04</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.269e-04</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>1.269e-04</td>\n",
       "      <td>1.269e-04</td>\n",
       "      <td>5.075e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011</td>\n",
       "      <td>4.106e-04</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.053e-04</td>\n",
       "      <td>0.000e+00</td>\n",
       "      <td>2.053e-04</td>\n",
       "      <td>2.053e-04</td>\n",
       "      <td>2.053e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0          1      2      3          4          5          6          7          8\n",
       "0  0.057  1.708e-03  0.998  0.005  8.540e-04  8.540e-04  0.000e+00  8.540e-04  4.270e-03\n",
       "1  0.004  3.361e-04  1.000  0.008  0.000e+00  1.680e-04  1.680e-04  3.361e-04  8.402e-04\n",
       "2  0.023  4.770e-04  1.000  0.006  4.770e-04  4.770e-04  4.770e-04  0.000e+00  1.431e-03\n",
       "3  0.006  2.537e-04  1.000  0.005  1.269e-04  0.000e+00  1.269e-04  1.269e-04  5.075e-04\n",
       "4  0.011  4.106e-04  1.000  0.005  2.053e-04  0.000e+00  2.053e-04  2.053e-04  2.053e-04"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "X = dataset.loc[:, dataset.columns != 'Risk_Code']\n",
    "scaler = Normalizer().fit(X)\n",
    "NormalizedX = pd.DataFrame(scaler.fit_transform(X))\n",
    "# summarize transformed data\n",
    "NormalizedX.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "# 5. Evaluate Algorithms and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.1'></a>\n",
    "## 5.1. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out validation dataset for the end\n",
    "Y= dataset[\"Risk_Code\"]\n",
    "X = dataset.loc[:, dataset.columns != 'Risk_Code']\n",
    "scaler = StandardScaler().fit(X)\n",
    "StandardisedX = pd.DataFrame(scaler.fit_transform(X))\n",
    "validation_size = 0.2\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.2'></a>\n",
    "## 5.2. Test Options and Evaluation Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "_cell_guid": "5702bc31-06bf-8b6a-42de-366a6b3311a8"
   },
   "outputs": [],
   "source": [
    "# test options for classification\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "#scoring ='neg_log_loss'\n",
    "#scoring = 'roc_auc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3'></a>\n",
    "## 5.3. Compare Models and Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3.1'></a>\n",
    "### 5.3.1. Common Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "_cell_guid": "772802f7-f4e4-84ee-6377-6464ab2e5da4"
   },
   "outputs": [],
   "source": [
    "# spot check the algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "#Neural Network\n",
    "models.append(('NN', MLPClassifier()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3.2'></a>\n",
    "### 5.3.2. Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensable Models \n",
    "# Boosting methods\n",
    "models.append(('AB', AdaBoostClassifier()))\n",
    "models.append(('GBM', GradientBoostingClassifier()))\n",
    "# Bagging methods\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('ET', ExtraTreesClassifier()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.3.3'></a>\n",
    "### 5.3.3. Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing the Deep Learning Classifier in case the Deep Learning Flag is Set to True\n",
    "#Set the following Flag to 1 if the Deep LEarning Models Flag has to be enabled\n",
    "EnableDLModelsFlag = 1\n",
    "if EnableDLModelsFlag == 1 :   \n",
    "    # Function to create model, required for KerasClassifier\n",
    "    def create_model(neurons=12, activation='relu', learn_rate = 0.01, momentum=0):\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(neurons, input_dim=X_train.shape[1], activation=activation))\n",
    "        model.add(Dense(2, activation=activation))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        # Compile model\n",
    "        optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model    \n",
    "    models.append(('DNN', KerasClassifier(build_fn=create_model, epochs=50, batch_size=10, verbose=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.create_model(neurons=12, activation='relu', learn_rate=0.01, momentum=0)>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-folds cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "_cell_guid": "a784ab4a-eb59-98cc-76cf-b55f382d057a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.688750 (0.036422)\n",
      "LDA: 0.696250 (0.039548)\n",
      "KNN: 0.625000 (0.052738)\n",
      "CART: 0.671250 (0.069383)\n",
      "NB: 0.701250 (0.038099)\n",
      "SVM: 0.688750 (0.037687)\n",
      "NN: 0.596250 (0.126250)\n",
      "AB: 0.720000 (0.031721)\n",
      "GBM: 0.722500 (0.041758)\n",
      "RF: 0.696250 (0.034483)\n",
      "ET: 0.688750 (0.035111)\n",
      "AB: 0.720000 (0.031721)\n",
      "GBM: 0.721250 (0.042957)\n",
      "RF: 0.703750 (0.047120)\n",
      "ET: 0.663750 (0.044529)\n",
      "DNN: 0.626250 (0.145285)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "_cell_guid": "67873e9d-bc9b-6963-f594-805f1efbfbb3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare algorithms\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "fig.set_size_inches(15,8)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "# 6. Model Tuning and Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "848ca488-b0fd-8e93-2e68-23d32c71d89c"
   },
   "source": [
    "Algorithm Tuning: Although some of the models show the most promising options. the grid search for Gradient Bossting Classifier is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.733750 using {'max_depth': 5, 'n_estimators': 20}\n",
      "#2 0.725000 (0.055057) with: {'max_depth': 3, 'n_estimators': 20}\n",
      "#3 0.721250 (0.050327) with: {'max_depth': 3, 'n_estimators': 180}\n",
      "#1 0.733750 (0.033564) with: {'max_depth': 5, 'n_estimators': 20}\n",
      "#4 0.712500 (0.044721) with: {'max_depth': 5, 'n_estimators': 180}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search: GradientBoosting Tuning\n",
    "'''\n",
    "n_estimators : int (default=100)\n",
    "    The number of boosting stages to perform. \n",
    "    Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance.\n",
    "max_depth : integer, optional (default=3)\n",
    "    maximum depth of the individual regression estimators. \n",
    "    The maximum depth limits the number of nodes in the tree. \n",
    "    Tune this parameter for best performance; the best value depends on the interaction of the input variables.\n",
    "\n",
    "''' \n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "n_estimators = [20,180]\n",
    "max_depth= [3,5]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\n",
    "model = GradientBoostingClassifier()\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, Y_train)\n",
    "\n",
    "#Print Results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "ranks = grid_result.cv_results_['rank_test_score']\n",
    "for mean, stdev, param, rank in zip(means, stds, params, ranks):\n",
    "    print(\"#%d %f (%f) with: %r\" % (rank, mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "# 7. Finalise the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the details above GBM might be worthy of further study, but for now SVM shows a lot of promise as a low complexity and stable model for this problem.\n",
    "\n",
    "Finalize Model with best parameters found during tuning step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1. Results on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=5,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare model\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model = GradientBoostingClassifier(n_estimators=20, max_depth=5) # rbf is default kernel\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "_cell_guid": "f9725666-3c21-69d1-ddf6-45e47d982444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.255\n",
      "[[ 51   0]\n",
      " [149   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      1.00      0.41        51\n",
      "           1       0.00      0.00      0.00       149\n",
      "\n",
      "   micro avg       0.26      0.26      0.26       200\n",
      "   macro avg       0.13      0.50      0.20       200\n",
      "weighted avg       0.07      0.26      0.10       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimate accuracy on validation set\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778    1\n",
       "334    0\n",
       "271    1\n",
       "802    1\n",
       "216    1\n",
       "408    1\n",
       "812    0\n",
       "94     1\n",
       "487    1\n",
       "170    0\n",
       "24     1\n",
       "242    0\n",
       "542    0\n",
       "930    1\n",
       "886    1\n",
       "426    1\n",
       "125    1\n",
       "453    1\n",
       "650    1\n",
       "913    1\n",
       "168    1\n",
       "776    1\n",
       "572    1\n",
       "848    1\n",
       "875    1\n",
       "590    1\n",
       "25     1\n",
       "484    1\n",
       "705    1\n",
       "889    1\n",
       "681    1\n",
       "13     0\n",
       "879    1\n",
       "277    1\n",
       "316    1\n",
       "299    1\n",
       "113    0\n",
       "962    1\n",
       "569    0\n",
       "60     1\n",
       "713    1\n",
       "907    1\n",
       "715    1\n",
       "725    1\n",
       "707    0\n",
       "758    1\n",
       "339    1\n",
       "733    1\n",
       "979    0\n",
       "99     1\n",
       "960    1\n",
       "289    0\n",
       "974    1\n",
       "34     1\n",
       "53     1\n",
       "319    1\n",
       "956    1\n",
       "906    1\n",
       "786    1\n",
       "941    1\n",
       "701    0\n",
       "454    0\n",
       "362    1\n",
       "997    1\n",
       "164    1\n",
       "473    1\n",
       "377    1\n",
       "372    1\n",
       "308    0\n",
       "845    1\n",
       "587    1\n",
       "905    1\n",
       "347    1\n",
       "689    1\n",
       "108    1\n",
       "693    1\n",
       "256    1\n",
       "718    1\n",
       "790    0\n",
       "472    0\n",
       "602    0\n",
       "810    1\n",
       "929    1\n",
       "351    0\n",
       "541    1\n",
       "228    0\n",
       "204    1\n",
       "624    0\n",
       "782    1\n",
       "966    0\n",
       "153    1\n",
       "676    1\n",
       "26     1\n",
       "57     1\n",
       "46     1\n",
       "98     1\n",
       "971    1\n",
       "739    0\n",
       "297    1\n",
       "972    0\n",
       "493    1\n",
       "140    1\n",
       "653    0\n",
       "643    1\n",
       "422    1\n",
       "259    1\n",
       "888    1\n",
       "63     0\n",
       "885    0\n",
       "954    1\n",
       "729    1\n",
       "509    1\n",
       "999    1\n",
       "685    1\n",
       "781    1\n",
       "146    1\n",
       "465    1\n",
       "917    0\n",
       "967    1\n",
       "270    1\n",
       "544    1\n",
       "403    1\n",
       "110    1\n",
       "171    1\n",
       "951    0\n",
       "801    1\n",
       "898    1\n",
       "9      0\n",
       "767    1\n",
       "205    1\n",
       "511    1\n",
       "743    1\n",
       "330    1\n",
       "932    1\n",
       "357    0\n",
       "61     1\n",
       "706    0\n",
       "237    0\n",
       "779    1\n",
       "984    1\n",
       "808    1\n",
       "361    1\n",
       "586    1\n",
       "531    0\n",
       "530    1\n",
       "109    1\n",
       "857    1\n",
       "305    1\n",
       "467    1\n",
       "736    0\n",
       "148    1\n",
       "938    0\n",
       "657    1\n",
       "836    1\n",
       "998    0\n",
       "485    0\n",
       "659    1\n",
       "128    1\n",
       "591    1\n",
       "558    0\n",
       "597    0\n",
       "499    1\n",
       "794    1\n",
       "321    0\n",
       "471    0\n",
       "594    0\n",
       "775    0\n",
       "482    1\n",
       "709    1\n",
       "466    0\n",
       "134    1\n",
       "232    1\n",
       "159    1\n",
       "355    0\n",
       "326    1\n",
       "396    1\n",
       "48     1\n",
       "74     0\n",
       "749    1\n",
       "799    1\n",
       "838    1\n",
       "996    1\n",
       "491    0\n",
       "344    1\n",
       "632    1\n",
       "614    0\n",
       "489    1\n",
       "893    1\n",
       "595    0\n",
       "518    1\n",
       "97     1\n",
       "283    1\n",
       "680    1\n",
       "285    1\n",
       "127    0\n",
       "371    1\n",
       "411    1\n",
       "644    1\n",
       "981    0\n",
       "365    1\n",
       "Name: Risk_Code, dtype: int32"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2. Variable Intuition/Feature Importance\n",
    "Looking at the details above GBM might be worthy of further study, but for now SVM shows a lot of promise as a low complexity and stable model for this problem.\n",
    "Let us look into the Feature Importance of the GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12173049 0.00929246 0.29864637 0.17190343 0.01309437 0.02368352\n",
      " 0.06295389 0.24438342 0.05431204]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAD8CAYAAADdeBV3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmYVdWZ7/HvD0RAQaKCWBK11KARRDGANo44ZegYR7xCNAETJXabqdPxNkY7URM72snt1kQNoonTNQE1aryQ6yygUYQCCwqIOIAmzhojijiWb/+xV5FjpYZTVefswyl+n+epp/ZZe62137UP1Ftr71X7KCIwMzOz8upR6QDMzMw2Bk64ZmZmOXDCNTMzy4ETrpmZWQ6ccM3MzHLghGtmZpYDJ1wzM7McOOGamZnlwAnXzMwsB5tUOgDbcAwcODBqa2srHYaZWVVZtGjRqxExqL16Tri2Xm1tLXV1dZUOw8ysqkh6pph6vqRsZmaWAydcMzOzHDjhmpmZ5cAJ18zMLAdeNGXrNTy3htqps9ut9/SFn88hGjOz7sUzXDMzsxw44ZqZmeXACbeKSVrbxr5xkmblGY+ZmbXOCdfMzCwHTrhVTpmfSFomqUHSiQW7t5B0q6QVkqZJ8vttZlYhXqVc/Y4DRgJ7AQOBhZLmpX37AMOAZ4A7Ut2bCxtLmgJMAei5RbuPAjUzs07yjKf6HQD8JiIaI+IlYC4wJu1bEBGrIqIR+E2q+xERMT0iRkfE6J6bDcgvajOzjYwTbvVTG/uinddmZpYTJ9zqNw84UVJPSYOAg4AFad8+knZK925PBB6sVJBmZhs7J9wqJWkT4F3gVmApsAS4D/jfEfFiqvYwcCGwDFid6pqZWQV40VT1Gg48FREBnJm+1ouIOcCc/MMyM7OWOOFWIUmnA98Evl3KfkcMGUCdn5NsZlYWTrhVKCKmAdMqHYeZmRXP93DNzMxy4IRrZmaWAydcMzOzHDjhmpmZ5cAJ18zMLAdOuGZmZjlwwjUzM8uBE66ZmVkOnHDNzMxy4IRrZmaWAydcMzOzHPhZyrZew3NrqJ06u8PtnvYHHpiZtcszXDMzsxw44ZqZmeXACbcTJJ0tabmkpZLqJe1bon57SbpQ0hOSlklaIOlzHWg/WdKlpYjFzMxKy/dwO0jSWOBI4FMR8a6kgcCmJer+h0ANsEfqezBwcIn6NjOzCvIMt+NqgFcj4l2AiHg1Ip6XNErSXEmLJN0pqUbSJpIWShoHIOnHki5oqVNJmwGnAd8o6PuliLgx7Z8oqSHNfC8qaHeKpMclzQX2LygfJOm36fgLJe2PmZlVjBNux90FbJ+S3OWSDpbUC/g5MD4iRgG/Ai6IiA+AycAvJB0BfBY4r5V+PwH8KSLeaL5D0nbARcChwEhgjKRjJNWk/vYHjgCGFTS7BPjviBgDHA9c1dJBJU2RVCeprnHdmo6dCTMzK5ovKXdQRKyVNAo4EDgEmAn8CNgDuFsSQE/ghVR/uaTrgf8HjI2I9zpx2DHAnIh4BUDSDcBBaV9h+Uxg11R+ODAsxQOwhaT+EfFms/FMB6YD9K4ZGp2IzczMiuCE2wkR0QjMAeZIagDOAJZHxNhWmowAXgcGt9Htk8AOLSVFQC01aAqnlfIeZAn+7TbamplZTnxJuYMk7SZpaEHRSOCPwKC0oKpptfHwtH0csDXZjPRnkj7WUr8RsQ74ZaqzaWpbI+lk4BHgYEkDJfUEJgJzU/k4SVuny9onFHR5F/D1grhHlmD4ZmbWSU64HdcPuFbSCklLye6bfh8YD1wkaQlQD+yXVjBfCHw1Ih4HLiW7t9qac4BXgBWSlgG3Aa9ExAvAWcD9wBJgcUT8LpWfCzwM3AMsLujrm8Do9KdLK4DTSzN8MzPrDEX4tp1letcMjZpJF3e4nR/taGYbM0mLImJ0e/V8D9fWGzFkAHVOnmZmZeGEWwGSbgV2alb8bxFxZyXiMTOz8nPCrYCIOLbSMZiZWb68aMrMzCwHTrhmZmY5cMI1MzPLgROumZlZDpxwzczMcuCEa2ZmlgMnXDMzsxw44ZqZmeXACdfMzCwHftKUrdfw3Bpqp84u+3H8YQdmtjHyDNfMzCwHTrhmZmY56LYJV9LaZq8nS7q0xMf4vaSPlbjPfSTNk7RS0mOSrpK0WQfaP50++N7MzDYgvofbBRHxj6XsT9Jg4CZgQkQ8LEnA8UB/YF0pj2VmZvnqtjPctkjaUdK9kpam7zuk8mskjS+otzZ9r0mzznpJyyQdmMqfljRQUq2kP0q6UtJySXdJ6pvqjEnHeVjSTyQtayO0M4BrI+JhgMjcHBEvSdpK0m2pr/mS9kz9b52O96ikKwAVxH+ypAUp7isk9SzxqTQzsyJ154TbNyWaekn1wPkF+y4FrouIPYEbgJ+109cXgTsjYiSwF1DfQp2hwGURMRx4nWxmCnA1cHpEjAUa2znOHsCiVvadBzyaYv4ecF0q/wHwYETsDdwONP3ysDtwIrB/irsROKl5p5KmSKqTVNe4bk074ZmZWWd150vKb6dEA2T3cIHR6eVY4Li0fT3wn+30tRD4laRewG0R0VLCXV1QvgioTfd3+0fEQ6n818CRHR5J5gBSEo+I+9LMdgBwUNNYImK2pL+m+ocBo4CF2ZVp+gIvN+80IqYD0wF61wyNTsZmZmbt6M4z3I5oSjQfkM5Jun+6KUBEzCNLbM8B10v6cgt9vFuw3Uj2y4xaqNeW5WRJsiUt9RXNvjevf21EjExfu0XEuR2Mx8zMSmRjTbgPARPS9knAg2n7af6W8I4GekF2zxd4OSKuBH4JfKqYg0TEX4E3Jf1DKprQVn2yS92TJO3bVJDuw24LzEuxImkc8GpEvNGs/HPAlqnpvcB4SdukfVulcZiZWQV050vKbfkm2SXiM4FXgFNS+ZXA7yQtIEtYb6XyccCZkt4H1gItzXBb81XgSklvAXOAVm+UpsVRE4CfpkT5IVlCvQU4F7ha0lKyFcuTUrPzgN9IWgzMBf6U+loh6RzgLkk9gPfJFmU904HYzcysRBTh23blJKlfRDStdp4K1ETEtyocVot61wyNmkkXl/04frSjmXUnkhZFxOj26m2sM9w8fV7SWWTn+hlgcmXDad2IIQOoczI0MysLJ9wyi4iZwMzCMkmfAS5qVnV1RBybW2BmZpYrJ9wKiIg7gTsrHYeZmeVnY12lbGZmlisnXDMzsxw44ZqZmeXACdfMzCwHTrhmZmY5cMI1MzPLgROumZlZDpxwzczMcuCEa2ZmlgM/acrWa3huDbVTZ1c6jLLzhyeYWSV4hmtmZpYDJ1wzM7McdOuEK6lRUr2kZZJukrRZpWNqj6R+kq6Q9JSk5ZLmSdq3A+3PlfTdcsZoZmYd160TLvB2RIyMiD2A94DTi20oqVL3t68CXgOGRsRwss/PHVihWMzMrES6e8It9ADwCUm1kpY1FUr6rqRz0/YcSf8haS7wLUnXSJom6QFJj0s6MtXrI+lqSQ2SHpV0SCofLmlBmlUvlTQ0lZ9cUH6FpJ4tBShpF2Bf4JyI+BAgIlZFxOy0/ztptr5M0rcL2p0taaWke4DdCvuTdIekRWkMnyzlCTUzs+JtFKuU02z1c8AdRVT/WEQcnNpdA9QCBwO7APdL+gRwBkBEjEhJ7C5Ju5LNoC+JiBskbQr0lLQ7cCKwf0S8L+ly4CTguhaOPRyoj4jGFsYwCjiFLCELeCT9YtADmADsTfZ+LgYWpWbTgdMj4ol0Wfpy4NBm/U4BpgD03GJQEafHzMw6o7sn3L6S6tP2A8Avge3aaTOz2esb02zzCUmrgE8CBwA/B4iIxyQ9A+wKPAycLenjwC0p0R0GjAIWSgLoC7zcibEcANwaEW8BSLoFOJAs4d4aEetS+e3pez9gP+CmdFyA3s07jYjpZImZ3jVDoxNxmZlZEbp7wn07IkYWFkj6gI9eSu/TrM1bzV43T0JBNsP8OxHxa0mPAJ8H7pR0aqp7bUScVUS8y4G9JPVouqRcGHob7VpKlD2A15uP38zMKmNjuofb5CVgG0lbS+oNHNlO/RMk9Uj3V3cGVgLzyC4Lky4l7wCslLQzsCoifgbcDuwJ3AuMl7RNqr+VpB1bOlBEPAXUAecpTUslDZV0dDrmMZI2k7Q5cCzZrH0ecKykvpL6A19Ifb0BrJZ0QupHkvbq+OkyM7NS6O4z3L+T7qOeDzwCrAYea6fJSmAuMJjsfug76T7sNEkNwAfA5Ih4V9KJwMmS3gdeBM6PiNcknUN2n7cH8D7ZPeBnWjneqcD/AZ6UtA74C3BmRCxO95QXpHpXRcSjAJJmAvWpzwcK+joJ+EU6fi9gBrCkiNNkZmYlpgjftmtNSnCzIuLmSseSh941Q6Nm0sWVDqPs/GhHMyslSYsiYnR79Ta6Ga61bsSQAdQ5GZmZlYUTbhsiYnK5+k6Lq5qvGv5SRDSU65hmZlY5TrgVEhFFP67RzMyq38a4StnMzCx3TrhmZmY5cMI1MzPLgROumZlZDpxwzczMcuCEa2ZmlgMnXDMzsxw44ZqZmeXACdfMzCwHftKUrdfw3Bpqp86udBgbDH/IgZmVkme4ZmZmOXDCNTMzy0FZEq6ksyUtl7RUUr2kDj+oX9JVkoZ1MY5/kfSOpAFd6acUJB1TzHgkfVfSY5KWSVoi6csdOMY4SbO6FqmZmZVDyROupLHAkcCnImJP4HDgzx3tJyJOjYgVXQxnIrAQOLaL/ZTCMUCbCVfS6cARwD4RsQdwEKAcYjMzszIrxwy3Bng1It4FiIhXI+J5Sd+XtDDN3KYrs7ukBU0NJdVKWpq250ganbbXSrogzfjmSxqcyndJrxdKOl/S2oK+dgH6AeeQJd6m8p6SfiqpIc3Av5HKx0h6KB1jgaT+kvpIujrVfVTSIanuZEmXFvQ5S9K41mKVtB9wFPCTNOPfpZVz9z3gnyPijXTu1kTEtanfw1IMDZJ+Jal3Kv9smhE/CBxXENPmqd7C1O7ojr+VZmZWKuVIuHcB20t6XNLlkg5O5ZdGxJg0c+sLHBkRfwQ2lbRzqnMicGMLfW4OzI+IvYB5wGmp/BLgkogYAzzfrM1E4DfAA8BukrZJ5VOAnYC90wz8BkmbAjOBb6VjHA68DZwBEBEjUn/XSurTzvj/LtaIeAi4HTgzIkZGxFPNG0nqD/RvZV8f4BrgxBTLJsA/pfIrgS8ABwLbFjQ7G7gvnZtDyJL95i30PUVSnaS6xnVr2hmamZl1VskTbkSsBUaRJbZXgJmSJgOHSHpEUgNwKDA8NbkR+F9p+0SyxNfce0DTvclFQG3aHgvclLZ/3azNBGBGRHwI3AKckMoPB6ZFxAcp3teA3YAXImJhKnsj7T8AuD6VPQY8A+zaziloLdb2CIhW9u0GrI6Ix9Pra8kuN38ylT8REQH834I2nwamSqoH5gB9gB2adxwR0yNidESM7rlZxW91m5l1W2X5O9yIaCT7IT8nJdivAXsCoyPiz5LOJUsAkCXYmyTdkjWNJ1ro8v2UUAAa24tb0p7AUOBuSQCbAquAy2g5sbWW7Fq7f/oBH/1lpXDW26FYm0TEG5LekrRzRKwqMg5oPUkLOD4iVhZzfDMzK69yLJraTdLQgqKRQNMP/Vcl9QPGN+1Ml1AbgX+n5dltW+YDx6ftCQXlE4FzI6I2fW0HDJG0I9kl79MlbZLi3Qp4DNhO0phU1j/tnweclMp2JZshrgSeBkZK6iFpe2CfImJ9E+jfTp0fA5dJ2iIdcwtJU1J8tZI+kep9CZibyncquCc8saCvO4FvKP3GIWnvImI0M7MyKcc93H5k9zpXpAVQw4Bzye41NgC3ka0cLjQTOJmW79+25dvAd9LCqxqg6SbkBODWZnVvTeVXAX8ClkpaAnwxIt4ju5z981R2N9ms9XKgZ5qlzwQmp8VgfwBWp/H8FFhcRKwzgDPTAqbWFk39ArgfWChpGVlSXRcR7wCnkF0JaAA+JLss/g7ZpfvZadHUMwV9/RDolca5LL02M7MK0d+uflYfSZsBb0dESJoATIwIr8btpN41Q6Nm0sWVDmOD4Uc7mlkxJC2KiNHt1av2ZymPAi5Nl01fB75S4Xiq2oghA6hzkjEzK4uqTrgR8QCwV6Xj6ChJlwH7Nyu+JCKurkQ8ZmZWflWdcKtVRJxR6RjMzCxf/vACMzOzHDjhmpmZ5cAJ18zMLAdOuGZmZjlwwjUzM8uBE66ZmVkOnHDNzMxy4IRrZmaWAydcMzOzHPhJU7Zew3NrqJ06u9JhWIX5QxvMysMzXDMzsxw44ZqZmeXACbeKSDpWUkj6ZKVjMTOzjnHCrS4TgQeBCZUOxMzMOsYJt0pI6kf2GbpfJSVcST0kXS5puaRZkn4vaXzaN0rSXEmLJN0pqaaC4ZuZbfSccKvHMcAdEfE48JqkTwHHAbXACOBUYCyApF7Az4HxETEK+BVwQUudSpoiqU5SXeO6NeUfhZnZRsp/FlQ9JgIXp+0Z6XUv4KaI+BB4UdL9af9uwB7A3ZIAegIvtNRpREwHpgP0rhkaZYvezGwj54RbBSRtDRwK7CEpyBJoALe21gRYHhFjcwrRzMza4UvK1WE8cF1E7BgRtRGxPbAaeBU4Pt3LHQyMS/VXAoMkrb/ELGl4JQI3M7OME251mMjfz2Z/C2wHPAssA64AHgHWRMR7ZEn6IklLgHpgv/zCNTOz5nxJuQpExLgWyn4G2erliFibLjsvABrS/nrgoDzjNDOz1jnhVr9Zkj4GbAr8MCJe7GxHI4YMoM7P0TUzKwsn3CrX0uzXzMw2PL6Ha2ZmlgMnXDMzsxw44ZqZmeXACdfMzCwHTrhmZmY5cMI1MzPLgROumZlZDpxwzczMcuCEa2ZmlgMnXDMzsxz40Y62XsNza6idOrvSYZiVxdN+TrhVmGe4ZmZmOXDCNTMzy4ETbolIapRUL2m5pCWSviOpZOdX0mRJ2xW8vkrSsFL1b2Zm5eV7uKXzdkSMBJC0DfBrYADwg2I7kNQzIhpb2T0ZWAY8DxARp3YpWjMzy5VnuGUQES8DU4CvKzNZ0qVN+yXNkjQuba+VdL6kR4Cxkr4vaaGkZZKmp/bjgdHADWkW3VfSHEmjUx8TJTWkNhcVHGetpAvSjHu+pMF5ngczM/sbJ9wyiYhVZOd3m3aqbg4si4h9I+JB4NKIGBMRewB9gSMj4magDjgpIkZGxNtNjdNl5ouAQ4GRwBhJxxT0PT8i9gLmAac1P7ikKZLqJNU1rlvTpTGbmVnrnHDLS0XUaQR+W/D6EEmPSGogS6LD22k/BpgTEa9ExAfADcBBad97wKy0vQiobd44IqZHxOiIGN1zswFFhGtmZp3he7hlImlnsmT6MvABH/3lpk/B9jtN920l9QEuB0ZHxJ8lndusbouHamPf+xERabsRv99mZhXjGW4ZSBoETCO7PBzA08BIST0kbQ/s00rTpuT6qqR+wPiCfW8C/Vto8whwsKSBknoCE4G5JRiGmZmVkGc8pdNXUj3Qi2xGez3wX2nfH4DVQAPZSuPFLXUQEa9LujLVexpYWLD7GmCapLeBsQVtXpB0FnA/2Wz39xHxu9INy8zMSkF/u+JoG7veNUOjZtLFlQ7DrCz8aEcrF0mLImJ0e/U8w7X1RgwZQJ1/KJmZlYXv4ZqZmeXACdfMzCwHTrhmZmY5cMI1MzPLgROumZlZDpxwzczMcuCEa2ZmlgMnXDMzsxw44ZqZmeXACdfMzCwHTrhmZmY5cMI1MzPLgT+8wNZreG4NtVNnVzoMM9tA+BOWSsszXDMzsxw44ZqZmeWgqIQraVtJMyQ9JWmFpN9LmiJpVlcDkDSupX4kHSVpahf7HiTpfUlf60o/pSCpVtIXi6i3j6R5klZKekzSVZI268BxnpY0sGvRmplZqbWbcCUJuBWYExG7RMQw4HvA4HIGFhG3R8SFXezmBGA+MLEEIXVVLdBmwpU0GLgJ+LeI2A3YHbgD6F/26MzMrKyKmeEeArwfEdOaCiKiHngA6Cfp5jQTuyElZySNkjRX0iJJd0qqSeWfkHSPpCWSFkvapfBAksZIelTSzpImS7o0lV8j6WeSHpK0StL4VN5D0uWSlkualWbe4wu6nAj8K/BxSUMKjvPZdPwlku5NZf0kXS2pQdJSScen8ompbJmkiwr6WFuwPV7SNW3FClwIHCipXtK/tHKuzwCujYiH03mOiLg5Il6StJWk21Js8yXtmY63taS70nm7AlBBXCdLWpCOeYWknm290WZmVj7FJNw9gEWt7Nsb+DYwDNgZ2F9SL+DnwPiIGAX8Crgg1b8BuCwi9gL2A15o6kjSfsA04OiIWNXCsWqAA4AjyZIXwHFkM8cRwKnA2IL+tge2jYgFwI3Aial8EHAlcHyK44TU5N+BNRExIiL2BO6TtB1wEXAoMBIYI+mYNs9W67FOBR6IiJER8d+ttGvrXJ8HPJpi+x5wXSr/AfBgROwN3A7skMa5exrz/hExEmgETmreabo1UCeprnHdmiKGZmZmndHVPwtaEBHPAkiqJ0t+r5MljrvThLcn8IKk/sCQiLgVICLeSe0gu3Q6Hfh0RDzfyrFui4gPgRXp0itkSe2mVP6ipPsL6k8gS7QAM4BfAv8F/AMwLyJWpzheS3UOT21I5X+VdBDZpfRXUqw3AAcBt7VzXlqKtasOAI5Psd2XZrYDUjzHpfLZkv6a6h8GjAIWpnPcF3i5eacRMZ3s3NO7ZmiUKFYzM2ummIS7HBjfyr53C7YbU38ClkfE2MKKkrZo4xgvAH3IZsytJdzCY6nZ95ZMBAZLaprVbSdpaGrTUmJpqbyt/gvr9iki1mIsJ0uSv2thX0v9RLPvzetfGxFndeD4ZmZWJsVcUr4P6C3ptKYCSWOAg1upvxIYJGlsqttL0vCIeAN4tumSrKTeBatvXwc+D/yHpHEdiP9B4Ph0L3cwMC71vRuweUQMiYjaiKgFfkw2g30YOFjSTqnuVqmvu4CvF4xxS+CRVHdguv85EZibqrwkaXdJPYBji4j1Tdpf/HQpMEnSvgVxnCxpW2Ae6ZJwOkevpnNaWP45YMvU9F5gvKRtmsYpacci4jQzszJoN+FGRJAllCOU/VnQcuBcWpmJRsR7ZDPiiyQtAerJ7tcCfAn4pqSlwEPAtgXtXgK+AFxWmHDa8VvgWWAZcAVZglxDlhhvbaHuxHR5eApwS4pvZtr/I2DLtDhqCXBIRLwAnAXcDywBFkdE0+xzKjCL7BeSF2jfUuCDtFCrxUVT6RxMAH6q7M+C/ggcCLxBds5Hp3N3ITApNTsPOEjSYuDTwJ9SXyuAc4C7Upu7ye4tm5lZBSjLp9VLUr+IWCtpa2AB2SKhFysdVzXqXTM0aiZdXOkwzGwD4Uc7FkfSoogY3V697vAs5VmSPgZsCvzQybbzRgwZQJ3/g5mZlUXVJ9yIGFfpGDpK0mfI/tyo0OqIKOZesJmZVaGqT7jVKCLuBO6sdBxmZpYff3iBmZlZDpxwzczMcuCEa2ZmlgMnXDMzsxw44ZqZmeXACdfMzCwHTrhmZmY5cMI1MzPLgROumZlZDvykKVuv4bk11E6dXekwzMxyldeHNHiGa2ZmloNun3AlbStpRvos3xWSfi9p1072NVnSpWn7dElfLijfrlndQZLel/S1ro+i8yQdI2lYJWMwM7NunnAlieyD6OdExC4RMQz4HjC4oE7PzvQdEdMi4rr0cjKwXbMqJwDzgYmd6b+EjgGccM3MKqxbJ1zgEOD9iJjWVBAR9UBPSfdL+jXQACDpZEkLJNVLuqIpEUs6RdLjkuYC+zf1I+lcSd+VNB4YDdyQ2vZNVSYC/wp8XNKQgnZrJV0kaZGkeyTtI2mOpFWSjkp1+ki6WlKDpEclHZLK18+w0+tZksYV9HuBpCWS5ksaLGk/4CjgJym2XUp9gs3MrDjdPeHuASxqZd8+wNkRMUzS7sCJwP4RMRJoBE6SVAOcR5Zoj6CFmWJE3AzUASdFxMiIeFvS9sC2EbEAuDH13WRzshn3KOBN4Eep72OB81OdM1LfI8gS97WS+rQz1s2B+RGxFzAPOC0iHgJuB85MsT3VTh9mZlYm3T3htmVBRKxO24cBo4CFkurT652BfcmS4ysR8R4ws8i+J5AlWoAZfPSy8nvAHWm7AZgbEe+n7dpUfgBwPUBEPAY8A7R33/k9YFbaXlTQV5skTZFUJ6mucd2aYpqYmVkndPc/C1oOjG9l31sF2wKujYizCitIOgaIThx3IjBY0knp9XaShkbEE2SXuJv6/BB4FyAiPpTU9H6olX4/4KO/JBXOegv7baTI9zYipgPTAXrXDO3MWM3MrAjdfYZ7H9Bb0mlNBZLGAAc3q3cvMF7SNqnOVpJ2BB4BxknaWlIvsoVQLXkT6J/a7gZsHhFDIqI2ImqBH5PNeos1Dzgp9bcrsAOwEngaGCmpR7psvU8Rfa2PzczMKqdbJ9w04zsWOCL9WdBy4Fzg+Wb1VgDnAHdJWgrcDdRExAup/sPAPcDiVg51DTAtXY7+CtnK6EK/pWOrlS8nW9jVQHYZe3JEvAv8AVhNdvn5p23EU2gGcGZafOVFU2ZmFaK/XYW0jV3vmqFRM+niSodhZparrj5pStKiiBjdXr1uPcM1MzPbUHT3RVPWASOGDKAup2eKmpltbDzDNTMzy4ETrpmZWQ6ccM3MzHLghGtmZpYDJ1wzM7Mc+O9wbT1Jb5I90aq7GQi8WukgSsxjqh7dcVzdcUzQ+XHtGBGD2qvkPwuyQiuL+ePtaiOprruNy2OqHt1xXN1xTFD+cfmSspmZWQ6ccM3MzHLghGuFplc6gDLpjuPymKpHdxxXdxwTlHlcXjRlZmaWA89wzczMcuCEu5GQ9FlJKyU9KWlqC/t7S5qZ9j8iqbZg31mpfKWkz+QZd1s6OyZJtZLellSfvqblHXtbihjXQZIWS/pA0vhm+yZJeiJ9Tcov6rZ1cUyNBe/V7flF3bYixvQdSSskLZV0r6QdC/ZtkO8TdHlc1fpenS6pIcX9oKRhBftK9/MvIvzVzb+AnsBTwM7ApsASYFizOv8MTEvbE4CZaXtYqt8b2Cn107PKx1QLLKv0GLowrlpgT+A6YHxB+VbAqvR9y7QSDrcRAAAC90lEQVS9ZTWPKe1bW+kxdHJMhwCbpe1/Kvj3t0G+T10dV5W/V1sUbB8F3JG2S/rzzzPcjcM+wJMRsSoi3gNmAEc3q3M0cG3avhk4TJJS+YyIeDciVgNPpv4qrStj2pC1O66IeDoilgIfNmv7GeDuiHgtIv4K3A18No+g29GVMW2oihnT/RGxLr2cD3w8bW+o7xN0bVwbqmLG9EbBy82BpsVNJf3554S7cRgC/Lng9bOprMU6EfEBsAbYusi2ldCVMQHsJOlRSXMlHVjuYDugK+e7mt+rtvSRVCdpvqRjShtap3V0TF8F/n8n2+apK+OCKn6vJJ0h6SngP4FvdqRtsfykqY1DS7O65svTW6tTTNtK6MqYXgB2iIi/SBoF3CZpeLPfciulK+e7mt+rtuwQEc9L2hm4T1JDRDxVotg6q+gxSToZGA0c3NG2FdCVcUEVv1cRcRlwmaQvAucAk4ptWyzPcDcOzwLbF7z+OPB8a3UkbQIMAF4rsm0ldHpM6fLQXwAiYhHZfZldyx5xcbpyvqv5vWpVRDyfvq8C5gB7lzK4TipqTJIOB84GjoqIdzvStkK6Mq6qfq8KzACaZuelfa8qfUPbX+X/IruSsYrspn/TooHhzeqcwUcXGN2Ytofz0UUDq9gwFk11ZUyDmsZAtpDiOWCrSo+p2HEV1L2Gv180tZpsIc6Wabvi4+rimLYEeqftgcATNFvwsqGOiSzZPAUMbVa+Qb5PJRhXNb9XQwu2vwDUpe2S/vyr+Bvsr3y+gH8EHk//Uc5OZeeT/YYK0Ae4iWxRwAJg54K2Z6d2K4HPVXosXR0TcDywPP1HWgx8odJj6eC4xpD95v0W8BdgeUHbr6TxPgmcUumxdHVMwH5AQ3qvGoCvVnosHRjTPcBLQH36un1Df5+6Mq4qf68uST8T6oH7KUjIpfz55ydNmZmZ5cD3cM3MzHLghGtmZpYDJ1wzM7McOOGamZnlwAnXzMwsB064ZmZmOXDCNTMzy4ETrpmZWQ7+ByBGQrbWF/3zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(rescaledX,Y_train)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3. Save Model for Later Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model Using Pickle\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765\n"
     ]
    }
   ],
   "source": [
    "# some time later...\n",
    "# load the model from disk\n",
    "loaded_model = load(open(filename, 'rb'))\n",
    "# estimate accuracy on validation set\n",
    "rescaledValidationX = scaler.transform(X_validation)\n",
    "predictions = model.predict(rescaledValidationX)\n",
    "result = accuracy_score(Y_validation, predictions)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 206,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
